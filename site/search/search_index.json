{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#what-is-codon","title":"What is Codon?","text":"<p>Codon is a high-performance Python implementation that compiles to native machine code without any runtime overhead. Typical speedups over vanilla Python are on the order of 10-100x or more, on a single thread. Codon's performance is typically on par with (and sometimes better than) that of C/C++. Unlike Python, Codon supports native multithreading, which can lead to speedups many times higher still.</p> <p>Think of Codon as Python reimagined for static, ahead-of-time compilation, built from the ground up with best possible performance in mind.</p>"},{"location":"#goals","title":"Goals","text":"<ul> <li> No learning curve: Be as close to CPython as possible in terms of syntax, semantics and libraries</li> <li> Top-notch performance: At least on par with low-level languages like C, C++ or Rust</li> <li> Hardware support: Full, seamless support for multicore programming, multithreading (no GIL!), GPU and more</li> <li> Optimizations: Comprehensive optimization framework that can target high-level Python constructs   and libraries</li> <li> Interoperability: Full interoperability with Python's ecosystem of packages and libraries</li> </ul>"},{"location":"#non-goals","title":"Non-goals","text":"<ul> <li> <p> Drop-in replacement for CPython: Codon is not a drop-in replacement for CPython. There are some   aspects of Python that are not suitable for static compilation \u2014 we don't support these in Codon.   There are ways to use Codon in larger Python codebases via its JIT decorator   or Python extension backend. Codon also supports   calling any Python module via its Python interoperability.   See also \"Differences with Python\" in the docs.</p> </li> <li> <p> New syntax and language constructs: We try to avoid adding new syntax, keywords or other language   features as much as possible. While Codon does add some new syntax in a couple places (e.g. to express   parallelism), we try to make it as familiar and intuitive as possible.</p> </li> </ul>"},{"location":"#how-it-works","title":"How it works","text":""},{"location":"#quick-start","title":"Quick start","text":"<p>Download and install Codon with this command:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://exaloop.io/install.sh)\"\n</code></pre> <p>After following the prompts, the <code>codon</code> command will be available to use. For example:</p> <ul> <li>To run a program: <code>codon run file.py</code></li> <li>To run a program with optimizations enabled: <code>codon run -release file.py</code></li> <li>To compile to an executable: <code>codon build -release file.py</code></li> <li>To generate LLVM IR: <code>codon build -release -llvm file.py</code></li> </ul> <p>Many more options are available and described in the docs.</p>"},{"location":"#examples","title":"Examples","text":""},{"location":"#basics","title":"Basics","text":"<p>Codon supports much of Python, and many Python programs will work with few if any modifications. Here's a simple script <code>fib.py</code> that computes the 40th Fibonacci number...</p> <pre><code>from time import time\n\ndef fib(n):\n    return n if n &lt; 2 else fib(n - 1) + fib(n - 2)\n\nt0 = time()\nans = fib(40)\nt1 = time()\nprint(f'Computed fib(40) = {ans} in {t1 - t0} seconds.')\n</code></pre> <p>... run through Python and Codon:</p> <pre><code>$ python3 fib.py\nComputed fib(40) = 102334155 in 17.979357957839966 seconds.\n$ codon run -release fib.py\nComputed fib(40) = 102334155 in 0.275645 seconds.\n</code></pre>"},{"location":"#using-python-libraries","title":"Using Python libraries","text":"<p>You can import and use any Python package from Codon via <code>from python import</code>. For example:</p> <pre><code>from python import matplotlib.pyplot as plt\ndata = [x**2 for x in range(10)]\nplt.plot(data)\nplt.show()\n</code></pre> <p>(Just remember to set the <code>CODON_PYTHON</code> environment variable to the CPython shared library, as explained in the the Python interoperability docs.)</p>"},{"location":"#parallelism","title":"Parallelism","text":"<p>Codon supports native multithreading via OpenMP. The <code>@par</code> annotation in the code below tells the compiler to parallelize the following <code>for</code>-loop, in this case using a dynamic schedule, chunk size of 100, and 16 threads.</p> <pre><code>from sys import argv\n\ndef is_prime(n):\n    factors = 0\n    for i in range(2, n):\n        if n % i == 0:\n            factors += 1\n    return factors == 0\n\nlimit = int(argv[1])\ntotal = 0\n\n@par(schedule='dynamic', chunk_size=100, num_threads=16)\nfor i in range(2, limit):\n    if is_prime(i):\n        total += 1\n\nprint(total)\n</code></pre> <p>Note that Codon automatically turns the <code>total += 1</code> statement in the loop body into an atomic reduction to avoid race conditions. Learn more in the multithreading docs.</p> <p>Codon also supports writing and executing GPU kernels. Here's an example that computes the Mandelbrot set:</p> <pre><code>import gpu\n\nMAX    = 1000  # maximum Mandelbrot iterations\nN      = 4096  # width and height of image\npixels = [0 for _ in range(N * N)]\n\ndef scale(x, a, b):\n    return a + (x/N)*(b - a)\n\n@gpu.kernel\ndef mandelbrot(pixels):\n    idx = (gpu.block.x * gpu.block.dim.x) + gpu.thread.x\n    i, j = divmod(idx, N)\n    c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))\n    z = 0j\n    iteration = 0\n\n    while abs(z) &lt;= 2 and iteration &lt; MAX:\n        z = z**2 + c\n        iteration += 1\n\n    pixels[idx] = int(255 * iteration/MAX)\n\nmandelbrot(pixels, grid=(N*N)//1024, block=1024)\n</code></pre> <p>GPU programming can also be done using the <code>@par</code> syntax with <code>@par(gpu=True)</code>. See the GPU programming docs for more details.</p>"},{"location":"#numpy-support","title":"NumPy support","text":"<p>Codon includes a feature-complete, fully-compiled native NumPy implementation. It uses the same API as NumPy, but re-implements everything in Codon itself, allowing for a range of optimizations and performance improvements.</p> <p>Here's an example NumPy program that approximates pi using random numbers...</p> <pre><code>import time\nimport numpy as np\n\nrng = np.random.default_rng(seed=0)\nx = rng.random(500_000_000)\ny = rng.random(500_000_000)\n\nt0 = time.time()\n# pi ~= 4 x (fraction of points in circle)\npi = ((x-1)**2 + (y-1)**2 &lt; 1).sum() * (4 / len(x))\nt1 = time.time()\n\nprint(f'Computed pi~={pi:.4f} in {t1 - t0:.2f} sec')\n</code></pre> <p>... run through Python and Codon:</p> <pre><code>$ python3 pi.py\nComputed pi~=3.1417 in 2.25 sec\n$ codon run -release pi.py\nComputed pi~=3.1417 in 0.43 sec\n</code></pre> <p>Codon can speed up NumPy code through general-purpose and NumPy-specific compiler optimizations, including inlining, fusion, memory allocation elision and more. Furthermore, Codon's NumPy implementation works with its multithreading and GPU capabilities, and can even integrate with PyTorch. Learn more in the Codon-NumPy docs.</p>"},{"location":"advanced/build/","title":"Building from source","text":""},{"location":"advanced/build/#summary","title":"Summary","text":"<p>Unless you really need to build Codon for whatever reason, we strongly recommend using pre-built binaries if possible.</p>"},{"location":"advanced/build/#dependencies","title":"Dependencies","text":"<p>Codon uses an LLVM fork based on LLVM 17. To build it, you can do:</p> <pre><code>git clone --depth 1 -b codon https://github.com/exaloop/llvm-project\ncmake -S llvm-project/llvm -B llvm-project/build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DLLVM_INCLUDE_TESTS=OFF \\\n    -DLLVM_ENABLE_RTTI=ON \\\n    -DLLVM_ENABLE_ZLIB=OFF \\\n    -DLLVM_ENABLE_ZSTD=OFF \\\n    -DLLVM_ENABLE_TERMINFO=OFF \\\n    -DLLVM_TARGETS_TO_BUILD=all\ncmake --build llvm-project/build\ncmake --install llvm-project/build --prefix=llvm-project/install\n</code></pre> <p>You can also add <code>-DLLVM_ENABLE_PROJECTS=clang</code> if you do not have <code>clang</code> installed on your system. We also recommend setting a local prefix during installation to avoid clashes with the system LLVM.</p>"},{"location":"advanced/build/#build","title":"Build","text":"<p>Codon requires <code>libgfortran</code>, the parent directory of which must be specified via the <code>CODON_SYSTEM_LIBRARIES</code> environment variable. For example, on macOS, with a <code>brew</code>-installed <code>libgfortran</code> (obtainable via <code>brew install gcc</code>):</p> <pre><code>export CODON_SYSTEM_LIBRARIES=/opt/homebrew/opt/gcc/lib/gcc/current\n</code></pre> <p>On Linux:</p> <pre><code>export CODON_SYSTEM_LIBRARIES=/usr/lib/x86_64-linux-gnu\n</code></pre> <p>Then, the following can generally be used to build Codon. The build process will automatically download and build several smaller dependencies.</p> <pre><code>cmake -S . -B build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DLLVM_DIR=$(llvm-config --cmakedir) \\\n    -DCMAKE_C_COMPILER=clang \\\n    -DCMAKE_CXX_COMPILER=clang++\ncmake --build build --config Release\ncmake --install build --prefix=install\n</code></pre> <p>This will produce the <code>codon</code> executable in the <code>install/bin</code> directory, as well as <code>codon_test</code> in the <code>build</code> directory which runs the test suite. Additionally, a number of shared libraries are produced in <code>install/lib/codon</code>:</p> <ul> <li><code>libcodonc</code>: The compiler library used by the <code>codon</code> command-line tool.</li> <li><code>libcodonrt</code>: The runtime library used during execution.</li> <li><code>libomp</code>: OpenMP runtime used to execute parallel code.</li> </ul> <p>\u26a0\ufe0f Warning: Make sure the <code>llvm-config</code> being used corresponds to Codon's LLVM. You can also use <code>-DLLVM_DIR=llvm-project/install/lib/cmake/llvm</code> on the first <code>cmake</code> command if you followed the instructions above for compiling LLVM.</p>"},{"location":"advanced/build/#gpu-support","title":"GPU support","text":"<p>Add <code>-DCODON_GPU=ON</code> to the first <code>cmake</code> command above to enable GPU support.</p>"},{"location":"advanced/build/#jupyter-support","title":"Jupyter support","text":"<p>To enable Jupyter support, you will need to build the Jupyter plugin:</p> <pre><code># Linux version:\ncmake -S jupyter -B jupyter/build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=clang \\\n    -DCMAKE_CXX_COMPILER=clang++ \\\n    -DLLVM_DIR=$(llvm-config --cmakedir) \\\n    -DCODON_PATH=install \\\n    -DOPENSSL_ROOT_DIR=$(openssl version -d | cut -d' ' -f2 | tr -d '\"') \\\n    -DOPENSSL_CRYPTO_LIBRARY=/usr/lib64/libssl.so \\\n    -DXEUS_USE_DYNAMIC_UUID=ON\n# n.b. OPENSSL_CRYPTO_LIBRARY might differ on your system.\n\n# On macOS, do this instead:\nOPENSSL_ROOT_DIR=/usr/local/opt/openssl cmake -S jupyter -B jupyter/build \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=clang \\\n    -DCMAKE_CXX_COMPILER=clang++ \\\n    -DLLVM_DIR=$(llvm-config --cmakedir) \\\n    -DCODON_PATH=install\n\n# Then:\ncmake --build jupyter/build\ncmake --install jupyter/build\n</code></pre>"},{"location":"advanced/gpu/","title":"GPU programming","text":""},{"location":"advanced/gpu/#summary","title":"Summary","text":"<p>Codon supports GPU programming through a native GPU backend. Currently, only Nvidia devices are supported. Here is a simple example:</p> <pre><code>import gpu\n\n@gpu.kernel\ndef hello(a, b, c):\n    i = gpu.thread.x\n    c[i] = a[i] + b[i]\n\na = [i for i in range(16)]\nb = [2*i for i in range(16)]\nc = [0 for _ in range(16)]\n\nhello(a, b, c, grid=1, block=16)\nprint(c)\n</code></pre> <p>which outputs:</p> <pre><code>[0, 3, 6, 9, 12, 15, 18, 21, 24, 27, 30, 33, 36, 39, 42, 45]\n</code></pre> <p>The same code can be written using Codon's <code>@par</code> syntax:</p> <pre><code>a = [i for i in range(16)]\nb = [2*i for i in range(16)]\nc = [0 for _ in range(16)]\n\n@par(gpu=True)\nfor i in range(16):\n    c[i] = a[i] + b[i]\n\nprint(c)\n</code></pre> <p>Below is a more comprehensive example for computing the Mandelbrot set, and plotting it using NumPy/Matplotlib:</p> <pre><code>from python import numpy as np\nfrom python import matplotlib.pyplot as plt\nimport gpu\n\nMAX    = 1000  # maximum Mandelbrot iterations\nN      = 4096  # width and height of image\npixels = [0 for _ in range(N * N)]\n\ndef scale(x, a, b):\n    return a + (x/N)*(b - a)\n\n@gpu.kernel\ndef mandelbrot(pixels):\n    idx = (gpu.block.x * gpu.block.dim.x) + gpu.thread.x\n    i, j = divmod(idx, N)\n    c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))\n    z = 0j\n    iteration = 0\n\n    while abs(z) &lt;= 2 and iteration &lt; MAX:\n        z = z**2 + c\n        iteration += 1\n\n    pixels[idx] = int(255 * iteration/MAX)\n\nmandelbrot(pixels, grid=(N*N)//1024, block=1024)\nplt.imshow(np.array(pixels).reshape(N, N))\nplt.show()\n</code></pre> <p>The GPU version of the Mandelbrot code is about 450 times faster than an equivalent CPU version.</p> <p>GPU kernels are marked with the <code>@gpu.kernel</code> annotation, and compiled specially in Codon's backend. Kernel functions can use the vast majority of features supported in Codon, with a couple notable exceptions:</p> <ul> <li> <p>Exception handling is not supported inside the kernel, meaning   kernel code should not throw or catch exceptions. <code>raise</code>   statements inside the kernel are marked as unreachable and   optimized out.</p> </li> <li> <p>Functionality related to I/O is not supported (e.g. you can't   open a file in the kernel).</p> </li> <li> <p>A few other modules and functions are not allowed, such as the   <code>re</code> module (which uses an external regex library) or the <code>os</code>   module.</p> </li> </ul> <p>\u26a0\ufe0f Warning: The GPU module is under active development. APIs and semantics might change between Codon releases.</p>"},{"location":"advanced/gpu/#invoking-the-kernel","title":"Invoking the kernel","text":"<p>The kernel can be invoked via a simple call with added <code>grid</code> and <code>block</code> parameters. These parameters define the grid and block dimensions, respectively. Recall that GPU execution involves a grid of (<code>X</code> x <code>Y</code> x <code>Z</code>) blocks where each block contains (<code>x</code> x <code>y</code> x <code>z</code>) executing threads. Device-specific restrictions on grid and block sizes apply.</p> <p>The <code>grid</code> and <code>block</code> parameters can be one of:</p> <ul> <li>Single integer <code>x</code>, giving dimensions <code>(x, 1, 1)</code></li> <li>Tuple of two integers <code>(x, y)</code>, giving dimensions <code>(x, y, 1)</code></li> <li>Tuple of three integers <code>(x, y, z)</code>, giving dimensions <code>(x, y, z)</code></li> <li>Instance of <code>gpu.Dim3</code> as in <code>Dim3(x, y, z)</code>, specifying the three dimensions</li> </ul>"},{"location":"advanced/gpu/#gpu-intrinsics","title":"GPU intrinsics","text":"<p>Codon's GPU module provides many of the same intrinsics that CUDA does:</p> Codon Description CUDA equivalent <code>gpu.thread.x</code> x-coordinate of current thread in block <code>threadId.x</code> <code>gpu.block.x</code> x-coordinate of current block in grid <code>blockIdx.x</code> <code>gpu.block.dim.x</code> x-dimension of block <code>blockDim.x</code> <code>gpu.grid.dim.x</code> x-dimension of grid <code>gridDim.x</code> <p>The same applies for the <code>y</code> and <code>z</code> coordinates. The <code>*.dim</code> objects are instances of <code>gpu.Dim3</code>.</p>"},{"location":"advanced/gpu/#math-functions","title":"Math functions","text":"<p>All the functions in the <code>math</code> module are supported in kernel functions, and are automatically replaced with GPU-optimized versions:</p> <pre><code>import math\nimport gpu\n\n@gpu.kernel\ndef hello(x):\n    i = gpu.thread.x\n    x[i] = math.sqrt(x[i])  # uses __nv_sqrt from libdevice\n\nx = [float(i) for i in range(10)]\nhello(x, grid=1, block=10)\nprint(x)\n</code></pre> <p>gives:</p> <pre><code>[0, 1, 1.41421, 1.73205, 2, 2.23607, 2.44949, 2.64575, 2.82843, 3]\n</code></pre>"},{"location":"advanced/gpu/#libdevice","title":"Libdevice","text":"<p>Codon uses libdevice for GPU-optimized math functions. The default libdevice path is <code>/usr/local/cuda/nvvm/libdevice/libdevice.10.bc</code>. An alternative path can be specified via the <code>-libdevice</code> compiler flag.</p>"},{"location":"advanced/gpu/#working-with-raw-pointers","title":"Working with raw pointers","text":"<p>By default, objects are converted entirely to their GPU counterparts, which have the same data layout as the original objects (although the Codon compiler might perform optimizations by swapping a CPU implementation of a data type with a GPU-optimized implementation that exposes the same API). This preserves all of Codon/Python's standard semantics within the kernel.</p> <p>It is possible to use a kernel with raw pointers via <code>gpu.raw</code>, which corresponds to how the kernel would be written in C++/CUDA:</p> <pre><code>import gpu\n\n@gpu.kernel\ndef hello(a, b, c):\n    i = gpu.thread.x\n    c[i] = a[i] + b[i]\n\na = [i for i in range(16)]\nb = [2*i for i in range(16)]\nc = [0 for _ in range(16)]\n\n# call the kernel with three int-pointer arguments:\nhello(gpu.raw(a), gpu.raw(b), gpu.raw(c), grid=1, block=16)\nprint(c)  # output same as first snippet's\n</code></pre> <p><code>gpu.raw</code> can avoid an extra pointer indirection, but outputs a Codon <code>Ptr</code> object, meaning the corresponding kernel parameters will not have the full list API, instead having the more limited <code>Ptr</code> API (which primarily just supports indexing/assignment).</p>"},{"location":"advanced/gpu/#object-conversions","title":"Object conversions","text":"<p>A hidden API is used to copy objects to and from the GPU device. This API consists of two new magic methods:</p> <ul> <li> <p><code>__to_gpu__(self)</code>: Allocates the necessary GPU memory and copies the object <code>self</code> to   the device.</p> </li> <li> <p><code>__from_gpu__(self, gpu_object)</code>: Copies the GPU memory of <code>gpu_object</code> (which is   a value returned by <code>__to_gpu__</code>) back to the CPU object <code>self</code>.</p> </li> </ul> <p>For primitive types like <code>int</code> and <code>float</code>, <code>__to_gpu__</code> simply returns <code>self</code> and <code>__from_gpu__</code> does nothing. These methods are defined for all the built-in types and are automatically generated for user-defined classes, so most objects can be transferred back and forth from the GPU seamlessly. A user-defined class that makes use of raw pointers or other low-level constructs will have to define these methods for GPU use. Please refer to the <code>gpu</code> module for implementation examples.</p>"},{"location":"advanced/gpu/#pargputrue","title":"<code>@par(gpu=True)</code>","text":"<p>Codon's <code>@par</code> syntax can be used to seamlessly parallelize existing loops on the GPU, without needing to explicitly write them as kernels. For loop nests, the <code>collapse</code> argument can be used to cover the entire iteration space on the GPU. For example, here is the Mandelbrot code above written using <code>@par</code>:</p> <pre><code>MAX    = 1000  # maximum Mandelbrot iterations\nN      = 4096  # width and height of image\npixels = [0 for _ in range(N * N)]\n\ndef scale(x, a, b):\n    return a + (x/N)*(b - a)\n\n@par(gpu=True, collapse=2)\nfor i in range(N):\n    for j in range(N):\n        c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))\n        z = 0j\n        iteration = 0\n\n        while abs(z) &lt;= 2 and iteration &lt; MAX:\n            z = z**2 + c\n            iteration += 1\n\n        pixels[i*N + j] = int(255 * iteration/MAX)\n</code></pre> <p>Note that the <code>gpu=True</code> option disallows shared variables (i.e. assigning out-of-loop variables in the loop body) as well as reductions. The other GPU-specific restrictions described here apply as well.</p>"},{"location":"advanced/gpu/#troubleshooting","title":"Troubleshooting","text":"<p>CUDA errors resulting in kernel abortion are printed, and typically arise from invalid code in the kernel, either via using exceptions or using unsupported modules/objects.</p>"},{"location":"advanced/ir/","title":"Intermediate representation","text":""},{"location":"advanced/ir/#summary","title":"Summary","text":"<p>After type checking but before native code generation, the Codon compiler makes use of a new intermediate representation called CIR, where a number of higher-level optimizations, transformations and analyses take place. CIR offers a comprehensive framework for writing new optimizations or analyses without having to deal with cumbersome abstract syntax trees (ASTs). In this section we'll give an overview of CIR, discuss the types of things you might want to use it for, and give a few examples.</p>"},{"location":"advanced/ir/#at-a-glance","title":"At a glance","text":"<p>Here is a small (simplified) example showcasing CIR in action. Consider the code:</p> <pre><code>def fib(n):\n    if n &lt; 2:\n        return 1\n    else:\n        return fib(n - 1) + fib(n - 2)\n</code></pre> <p>When instantiated with an <code>int</code> argument, the following IR gets produced (the names have been cleaned up for simplicity):</p> <pre><code>(bodied_func\n  '\"fib[int]\"\n  (type '\"fib[int]\")\n  (args (var '\"n\" (type '\"int\") (global false)))\n  (vars)\n  (series\n    (if (call '\"int.__lt__[int,int]\" '\"n\" 2)\n      (series (return 1))\n      (series\n        (return\n          (call\n            '\"int.__add__[int,int]\"\n            (call\n              '\"fib[int]\"\n              (call '\"int.__sub__[int,int]\" '\"n\" 1))\n            (call\n              '\"fib[int]\"\n              (call '\"int.__sub__[int,int]\" '\"n\" 2))))))))\n</code></pre> <p>A few interesting points to consider:</p> <ul> <li>CIR is hierarchical like ASTS, but unlike ASTs it uses a vastly reduced   set of nodes, making it much easier to work with and reason about.</li> <li>Operators are expressed as function calls. In fact, CIR has no explicit   concept of <code>+</code>, <code>-</code>, etc. and instead expresses these via their corresponding   magic methods (<code>__add__</code>, <code>__sub__</code>, etc.).</li> <li>CIR has no concept of generic types. By the time CIR is generated, all types   need to have been resolved.</li> </ul>"},{"location":"advanced/ir/#structure","title":"Structure","text":"<p>CIR is comprised of a set of nodes, each with a specific semantic meaning. There are nodes for representing constants (e.g. <code>42</code>), instructions (e.g. <code>call</code>) control flow (e.g. <code>if</code>), types (e.g. <code>int</code>) and so on.</p> <p>Here is a table showing the different types of nodes, LLVM IR equivalents, and some examples:</p> Node LLVM equivalent Examples <code>Node</code> n/a all of the below <code>Module</code> <code>Module</code> n/a <code>Type</code> <code>Type</code> <code>IntType</code>, <code>FuncType</code>, <code>RefType</code> <code>Var</code> <code>AllocaInst</code> <code>Var</code>, <code>Func</code> <code>Func</code> <code>Function</code> <code>BodiedFunc</code>, <code>ExternalFunc</code>, <code>LLVMFunc</code> <code>Value</code> <code>Value</code> all of the below <code>Const</code> <code>Constant</code> <code>IntConst</code>, <code>FloatConst</code>, <code>StringConst</code> <code>Instr</code> <code>Instruction</code> <code>CallInstr</code>, <code>TernaryInstr</code>, <code>ThrowInstr</code> <code>Flow</code> n/a <code>IfFlow</code>, <code>WhileFlow</code>, <code>ForFlow</code>"},{"location":"advanced/ir/#uses","title":"Uses","text":"<p>CIR provides a framework for doing program optimizations, analyses and transformations. These operations are collectively known as IR passes.</p> <p>A number of built-in passes and other functionalities are provided by CIR. These can be used as building blocks to create new passes. Examples include:</p> <ul> <li>Control-flow graph creation</li> <li>Reaching definitions</li> <li>Dominator analysis</li> <li>Side effect analysis</li> <li>Constant propagation and folding</li> <li>Canonicalization</li> <li>Inlining and outlining</li> <li>Python-specific optimizations targeting several common Python idioms</li> </ul> <p>We're regularly adding new standard passes, so this list is always growing.</p>"},{"location":"advanced/ir/#an-example","title":"An example","text":"<p>Let's look at a real example. Imagine we want to write a pass that transforms expressions of the form <code>&lt;int const&gt; + &lt;int const&gt;</code> into a single <code>&lt;int const&gt;</code> denoting the result. In other words, a simple form of constant folding that only looks at addition on integers. The resulting pass would like this:</p> <pre><code>#include \"codon/cir/transform/pass.h\"\n\nusing namespace codon::ir;\n\nclass MyAddFolder : public transform::OperatorPass {\npublic:\n  static const std::string KEY;\n  std::string getKey() const override { return KEY; }\n\n  void handle(CallInstr *v) override {\n    auto *f = util::getFunc(v-&gt;getCallee());\n    if (!f || f-&gt;getUnmangledName() != \"__add__\" || v-&gt;numArgs() != 2)\n        return;\n\n    auto *lhs = cast&lt;IntConst&gt;(v-&gt;front());\n    auto *rhs = cast&lt;IntConst&gt;(v-&gt;back());\n\n    if (lhs &amp;&amp; rhs) {\n      auto sum = lhs-&gt;getVal() + rhs-&gt;getVal();\n      v-&gt;replaceAll(v-&gt;getModule()-&gt;getInt(sum));\n    }\n  }\n};\n\nconst std::string MyAddFolder::KEY = \"my-add-folder\";\n</code></pre>"},{"location":"advanced/ir/#how-does-this-work","title":"How does this work?","text":"<p>So how does this actually work, and what do the different components mean? Here are some notable points:</p> <ul> <li>Most passes can inherit from <code>transform::OperatorPass</code>. <code>OperatorPass</code> is a combination   of an <code>Operator</code> and a <code>Pass</code>. An <code>Operator</code> is a utility visitor that provides hooks for   handling all the different node types (i.e. through the <code>handle()</code> methods). <code>Pass</code> is the   base class representing a generic pass, which simply provides a <code>run()</code> method that takes   a module.</li> <li>Because of this, <code>MyAddFolder::handle(CallInstr *)</code> will be called on every call instruction   in the module.</li> <li>Within our <code>handle()</code>, we first check to see if the function being called is <code>__add__</code>, indicating   addition (in practice there would be a more specific check to make sure this is the <code>__add__</code>),   and if so we extract the first and second arguments.</li> <li>We cast these arguments to <code>IntConst</code>. If the results are non-null, then both arguments were in fact   integer constants, meaning we can replace the original call instruction with a new constant that   represents the result of the addition. In CIR, all nodes are \"replaceable\" via a <code>replaceAll()</code> method.</li> <li>Lastly, notice that all passes have a <code>KEY</code> field to uniquely identify them.</li> </ul>"},{"location":"advanced/ir/#bidirectionality","title":"Bidirectionality","text":"<p>An important and often very useful feature of CIR is that it is bidirectional, meaning it's possible to return to the type checking stage to generate new IR nodes that were not initially present in the module. For example, imagine that your pass needs to use a <code>List</code> with some new element type; that list's methods need to be instantiated by the type checker for use in CIR. In practice this bidirectionality often lets you write large parts of your optimization or transformation in Codon, and pull out the necessary functions or types as needed in the pass.</p> <p>CIR's <code>Module</code> class has three methods to enable this feature:</p> <pre><code>  /// Gets or realizes a function.\n  /// @param funcName the function name\n  /// @param args the argument types\n  /// @param generics the generics\n  /// @param module the module of the function\n  /// @return the function or nullptr\n  Func *getOrRealizeFunc(const std::string &amp;funcName, std::vector&lt;types::Type *&gt; args,\n                         std::vector&lt;types::Generic&gt; generics = {},\n                         const std::string &amp;module = \"\");\n\n  /// Gets or realizes a method.\n  /// @param parent the parent class\n  /// @param methodName the method name\n  /// @param rType the return type\n  /// @param args the argument types\n  /// @param generics the generics\n  /// @return the method or nullptr\n  Func *getOrRealizeMethod(types::Type *parent, const std::string &amp;methodName,\n                           std::vector&lt;types::Type *&gt; args,\n                           std::vector&lt;types::Generic&gt; generics = {});\n\n  /// Gets or realizes a type.\n  /// @param typeName the type name\n  /// @param generics the generics\n  /// @param module the module of the type\n  /// @return the function or nullptr\n  types::Type *getOrRealizeType(const std::string &amp;typeName,\n                                std::vector&lt;types::Generic&gt; generics = {},\n                                const std::string &amp;module = \"\");\n</code></pre> <p>Let's see bidirectionality in action. Consider the following Codon code:</p> <pre><code>def foo(x):\n    return x*3 + x\n\ndef validate(x, y):\n    assert y == x*4\n\na = foo(10)\nb = foo(1.5)\nc = foo('a')\n</code></pre> <p>Assume we want our pass to insert a call to <code>validate()</code> after each assignment that takes the assigned variable and the argument passed to <code>foo()</code>. We would do something like the following:</p> <pre><code>#include \"codon/cir/transform/pass.h\"\n\nusing namespace codon::ir;\n\nclass ValidateFoo : public transform::OperatorPass {\npublic:\n  static const std::string KEY;\n  std::string getKey() const override { return KEY; }\n\n  void handle(AssignInstr *v) {\n    auto *M = v-&gt;getModule();\n    auto *var = v-&gt;getLhs();\n    auto *call = cast&lt;CallInstr&gt;(v-&gt;getRhs());\n    if (!call)\n      return;\n\n    auto *foo = util::getFunc(call-&gt;getCallee());\n    if (!foo || foo-&gt;getUnmangledName() != \"foo\")\n      return;\n\n    auto *arg1 = call-&gt;front();         // argument of 'foo' call\n    auto *arg2 = M-&gt;Nr&lt;VarValue&gt;(var);  // result of 'foo' call\n    auto *validate =\n      M-&gt;getOrRealizeFunc(\"validate\", {arg1-&gt;getType(), arg2-&gt;getType()});\n    auto *validateCall = util::call(validate, {arg1, arg2});\n\n    insertAfter(validateCall);  // call 'validate' after 'foo'\n  }\n};\n\nconst std::string ValidateFoo::KEY = \"validate-foo\";\n</code></pre> <p>Note that <code>insertAfter</code> is a convenience method of <code>Operator</code> that inserts the given node \"after\" the node being visited (along with <code>insertBefore</code> which inserts before the node being visited).</p> <p>Running this pass on the snippet above, we would get:</p> <pre><code>a = foo(10)\nvalidate(10, a)\n\nb = foo(1.5)\nvalidate(1.5, b)\n\nc = foo('a')\nvalidate('a', c)\n</code></pre> <p>Notice that we used <code>getOrRealizeFunc</code> to create three different instances of <code>validate</code>: one for <code>int</code> arguments, one for <code>float</code> arguments and finally one for <code>str</code> arguments.</p>"},{"location":"advanced/ir/#extending-the-ir","title":"Extending the IR","text":"<p>CIR is extensible, and it is possible to add new constants, instructions, flows and types. This can be done by subclassing the corresponding custom base class; to create a custom type, for example, you would subclass <code>CustomType</code>. Let's look at an example where we extend CIR to add a 32-bit float type:</p> <pre><code>using namespace codon::ir;\n\n#include \"codon/cir/dsl/nodes.h\"\n#include \"codon/cir/llvm/llvisitor.h\"\n\nclass Builder : public dsl::codegen::TypeBuilder {\npublic:\n  llvm::Type *buildType(LLVMVisitor *v) override {\n    return v-&gt;getBuilder()-&gt;getFloatTy();\n  }\n\n  llvm::DIType *buildDebugType(LLVMVisitor *v) override {\n    auto *module = v-&gt;getModule();\n    auto &amp;layout = module-&gt;getDataLayout();\n    auto &amp;db = v-&gt;getDebugInfo();\n    auto *t = buildType(v);\n    return db.builder-&gt;createBasicType(\n           \"float_32\",\n           layout.getTypeAllocSizeInBits(t),\n           llvm::dwarf::DW_ATE_float);\n  }\n};\n\nclass Float32 : public dsl::CustomType {\npublic:\n  std::unique_ptr&lt;TypeBuilder&gt; getBuilder() const override {\n    return std::make_unique&lt;Builder&gt;();\n  }\n};\n</code></pre> <p>Notice that, in order to specify how to generate code for our <code>Float32</code> type, we create a <code>TypeBuilder</code> subclass with methods for building the corresponding LLVM IR type. There is also a <code>ValueBuilder</code> for new constants and converting them to LLVM IR, as well as a <code>CFBuilder</code> for new instructions and creating control-flow graphs out of them.</p> <p>\u2139\ufe0f Info: When subclassing nodes other than types (e.g. instructions, flows, etc.), be sure to use the <code>AcceptorExtend</code> CRTP class, as in <code>class MyNewInstr : public AcceptorExtend&lt;MyNewInstr, dsl::CustomInstr&gt;</code>.</p>"},{"location":"advanced/ir/#utilities","title":"Utilities","text":"<p>The <code>codon/cir/util/</code> directory has a number of utility and generally helpful functions, for things like cloning IR, inlining/outlining, matching and more. <code>codon/cir/util/irtools.h</code> in particular has many helpful functions for performing various common tasks. If you're working with CIR, be sure to take a look at these functions to make your life easier!</p>"},{"location":"advanced/ir/#standard-pass-pipeline","title":"Standard pass pipeline","text":"<p>These standard sets of passes are run in <code>release</code>-mode:</p> <ul> <li> <p>Python-specific optimizations: a series of passes to optimize common Python patterns and   idioms. Examples include dictionary updates of the form <code>d[k] = d.get(k, x) &lt;op&gt; y</code>, and   optimizing them to do just one access into the dictionary, as well as optimizing repeated   string concatenations or various I/O patterns.</p> </li> <li> <p>Imperative <code>for</code>-loop lowering: loops of the form <code>for i in range(a, b, c)</code> (with <code>c</code> constant)   are lowered to a special IR node, since these loops are important for e.g. multithreading later.</p> </li> <li> <p>A series of program analyses whose results are available to later passes:</p> </li> <li>Control-flow analysis</li> <li>Reaching definition analysis</li> <li>Dominator analysis</li> <li> <p>Capture (or escape) analysis</p> </li> <li> <p>Parallel loop lowering for multithreading or GPU</p> </li> <li> <p>Constant propagation and folding. This also includes dead code elimination and (in non-JIT mode)   global variable demotion.</p> </li> </ul> <p>Codon plugins can inject their own passes into the pipeline as well.</p>"},{"location":"advanced/parallel/","title":"Parallelism and multithreading","text":""},{"location":"advanced/parallel/#summary","title":"Summary","text":"<p>Codon supports parallelism and multithreading via OpenMP out of the box. Here\\'s an example:</p> <pre><code>@par\nfor i in range(10):\n    import threading as thr\n    print('hello from thread', thr.get_ident())\n</code></pre> <p>By default, parallel loops will use all available threads, or use the number of threads specified by the <code>OMP_NUM_THREADS</code> environment variable. A specific thread number can be given directly on the <code>@par</code> line as well:</p> <pre><code>@par(num_threads=5)\nfor i in range(10):\n    import threading as thr\n    print('hello from thread', thr.get_ident())\n</code></pre> <p><code>@par</code> supports several OpenMP parameters, including:</p> <ul> <li><code>num_threads</code> (int): the number of threads to use when running the     loop</li> <li><code>schedule</code> (str): either static, dynamic, guided, auto or     runtime</li> <li><code>chunk_size</code> (int): chunk size when partitioning loop iterations</li> <li><code>ordered</code> (bool): whether the loop iterations should be executed in     the same order</li> <li><code>collapse</code> (int): number of loop nests to collapse into a single     iteration space</li> </ul> <p>Other OpenMP parameters like <code>private</code>, <code>shared</code> or <code>reduction</code>, are inferred automatically by the compiler. For example, the following loop</p> <pre><code>a = 0\n@par\nfor i in range(N):\n    a += foo(i)\n</code></pre> <p>will automatically generate a reduction for variable <code>a</code>.</p> <p>\u26a0\ufe0f Warning: Modifying shared objects like lists or dictionaries within a parallel section needs to be done with a lock or critical section. See below for more details.</p> <p>Here is an example that finds the number of primes up to a user-defined limit, using a parallel loop on 16 threads with a dynamic schedule and chunk size of 100:</p> <pre><code>from sys import argv\n\ndef is_prime(n):\n    factors = 0\n    for i in range(2, n):\n        if n % i == 0:\n            factors += 1\n    return factors == 0\n\nlimit = int(argv[1])\ntotal = 0\n\n@par(schedule='dynamic', chunk_size=100, num_threads=16)\nfor i in range(2, limit):\n    if is_prime(i):\n        total += 1\n\nprint(total)\n</code></pre> <p>Static schedules work best when each loop iteration takes roughly the same amount of time, whereas dynamic schedules are superior when each iteration varies in duration. Since counting the factors of an integer takes more time for larger integers, we use a dynamic schedule here.</p> <p><code>@par</code> also supports C/C++ OpenMP pragma strings. For example, the <code>@par</code> line in the above example can also be written as:</p> <pre><code># same as: @par(schedule='dynamic', chunk_size=100, num_threads=16)\n@par('schedule(dynamic, 100) num_threads(16)')\n</code></pre>"},{"location":"advanced/parallel/#different-kinds-of-loops","title":"Different kinds of loops","text":"<p><code>for</code>-loops can iterate over arbitrary generators, but OpenMP\\'s parallel loop construct only applies to imperative for-loops of the form <code>for i in range(a, b, c)</code> (where <code>c</code> is constant). For general parallel for-loops of the form <code>for i in some_generator()</code>, a task-based approach is used instead, where each loop iteration is executed as an independent task.</p> <p>The Codon compiler also converts iterations over lists (<code>for a in some_list</code>) to imperative for-loops, meaning these loops can be executed using OpenMP\\'s loop parallelism.</p>"},{"location":"advanced/parallel/#custom-reductions","title":"Custom reductions","text":"<p>Codon can automatically generate efficient reductions for <code>int</code> and <code>float</code> values. For other data types, user-defined reductions can be specified. A class that supports reductions must include:</p> <ul> <li>A default constructor that represents the zero value</li> <li>An <code>__add__</code> method (assuming <code>+</code> is used as the reduction operator)</li> </ul> <p>Here is an example for reducing a new <code>Vector</code> type:</p> <pre><code>@tuple\nclass Vector:\n    x: int\n    y: int\n\n    def __new__():\n        return Vector(0, 0)\n\n    def __add__(self, other: Vector):\n        return Vector(self.x + other.x, self.y + other.y)\n\nv = Vector()\n@par\nfor i in range(100):\n    v += Vector(i,i)\nprint(v)  # (x: 4950, y: 4950)\n</code></pre>"},{"location":"advanced/parallel/#openmp-constructs","title":"OpenMP constructs","text":"<p>All of OpenMP\\'s API functions are accessible directly in Codon. For example:</p> <pre><code>import openmp as omp\nprint(omp.get_num_threads())\nomp.set_num_threads(32)\n</code></pre> <p>OpenMP\\'s critical, master, single and ordered constructs can be applied via the corresponding decorators:</p> <pre><code>import openmp as omp\n\n@omp.critical\ndef only_run_by_one_thread_at_a_time():\n    print('critical!', omp.get_thread_num())\n\n@omp.master\ndef only_run_by_master_thread():\n    print('master!', omp.get_thread_num())\n\n@omp.single\ndef only_run_by_single_thread():\n    print('single!', omp.get_thread_num())\n\n@omp.ordered\ndef run_ordered_by_iteration(i):\n    print('ordered!', i)\n\n@par(ordered=True)\nfor i in range(100):\n    only_run_by_one_thread_at_a_time()\n    only_run_by_master_thread()\n    only_run_by_single_thread()\n    run_ordered_by_iteration(i)\n</code></pre>"},{"location":"advanced/parallel/#finer-grained-locking","title":"Finer-grained Locking","text":"<p>For finer-grained locking, consider using the locks from the <code>threading</code> module:</p> <pre><code>from threading import Lock\nlock = Lock()  # or RLock for reentrant lock\n\n@par\nfor i in range(100):\n    with lock:\n        print('only one thread at a time allowed here')\n</code></pre>"},{"location":"advanced/pipelines/","title":"Pipelines","text":""},{"location":"advanced/pipelines/#summary","title":"Summary","text":"<p>Codon extends the core Python language with a pipe operator. You can chain multiple functions and generators to form a pipeline. Pipeline stages can be regular functions or generators. In the case of standard functions, the function is simply applied to the input data and the result is carried to the remainder of the pipeline, akin to F#\\'s functional piping. If, on the other hand, a stage is a generator, the values yielded by the generator are passed lazily to the remainder of the pipeline, which in many ways mirrors how piping is implemented in Bash. Note that Codon ensures that generator pipelines do not collect any data unless explicitly requested, thus allowing the processing of terabytes of data in a streaming fashion with no memory and minimal CPU overhead.</p> <pre><code>def add1(x):\n    return x + 1\n\n2 |&gt; add1  # 3; equivalent to add1(2)\n\ndef calc(x, y):\n    return x + y**2\n2 |&gt; calc(3)       # 11; equivalent to calc(2, 3)\n2 |&gt; calc(..., 3)  # 11; equivalent to calc(2, 3)\n2 |&gt; calc(3, ...)  # 7; equivalent to calc(3, 2)\n\ndef gen(i):\n    for i in range(i):\n        yield i\n\n5 |&gt; gen |&gt; print # prints 0 1 2 3 4 separated by newline\nrange(1, 4) |&gt; iter |&gt; gen |&gt; print(end=' ')  # prints 0 0 1 0 1 2 without newline\n[1, 2, 3] |&gt; print   # prints [1, 2, 3]\nrange(100000000) |&gt; print  # prints range(0, 100000000)\nrange(100000000) |&gt; iter |&gt; print  # not only prints all those numbers, but it uses almost no memory at all\n</code></pre> <p>Codon will chain anything that implements <code>__iter__</code>, and the compiler will optimize out generators whenever possible. Combinations of pipes and generators can be used to implement efficient streaming pipelines.</p> <p>\u26a0\ufe0f Warning: The Codon compiler may perform optimizations that change the order of elements passed through a pipeline. Therefore, it is best to not rely on order when using pipelines. If order needs to be maintained, consider using a regular loop or passing an index alongside each element sent through the pipeline.</p>"},{"location":"advanced/pipelines/#parallel-pipelines","title":"Parallel pipelines","text":"<p>CPython and many other implementations alike cannot take advantage of parallelism due to the infamous global interpreter lock, a mutex that prevents multiple threads from executing Python bytecode at once. Unlike CPython, Codon has no such restriction and supports full multithreading. To this end, Codon supports a parallel pipe operator <code>||&gt;</code>, which is semantically similar to the standard pipe operator except that it allows the elements sent through it to be processed in parallel by the remainder of the pipeline. Hence, turning a serial program into a parallel one often requires the addition of just a single character in Codon. Further, a single pipeline can contain multiple parallel pipes, resulting in nested parallelism.</p> <pre><code>range(100000) |&gt; iter ||&gt; print              # prints all these numbers, probably in random order\nrange(100000) |&gt; iter ||&gt; process ||&gt; clean  # runs process in parallel, and then cleans data in parallel\n</code></pre> <p>Codon will automatically schedule the <code>process</code> and <code>clean</code> functions to execute as soon as possible. You can control the number of threads via the <code>OMP_NUM_THREADS</code> environment variable.</p> <p>Internally, the Codon compiler uses an OpenMP task backend to generate code for parallel pipelines. Logically, parallel pipe operators are similar to parallel-for loops: the portion of the pipeline after the parallel pipe is outlined into a new function that is called by the OpenMP runtime task spawning routines (as in <code>#pragma omp task</code> in C++), and a synchronization point (<code>#pragma omp taskwait</code>) is added after the outlined segment.</p>"},{"location":"interop/cpp/","title":"C/C++ integration","text":""},{"location":"interop/cpp/#summary","title":"Summary","text":"<p>Calling C/C++ from Codon is quite easy with <code>from C import</code>, but Codon can also be called from C/C++ code. To make a Codon function externally visible, simply annotate it with <code>@export</code>:</p> <pre><code>@export\ndef foo(n: int):\n    for i in range(n):\n        print(i * i)\n    return n * n\n</code></pre> <p>Note that only top-level, non-generic functions can be exported. Now we can create a shared library containing <code>foo</code> (assuming source file foo.codon):</p> <pre><code>codon build --relocation-model=pic --lib -o libfoo.so foo.codon\n</code></pre> <p>Now we can call <code>foo</code> from a C program (if you're using C++, mark the Codon function as <code>extern \"C\"</code>):</p> <pre><code>#include &lt;stdint.h&gt;\n#include &lt;stdio.h&gt;\n\nint64_t foo(int64_t);\n// In C++, it would be:\n// extern \"C\" int64_t foo(int64_t);\n\nint main() {\n  printf(\"%llu\\n\", foo(10));\n}\n</code></pre> <p>Compile:</p> <pre><code>gcc -o foo -L. -lfoo foo.c  # or g++ if using C++\n</code></pre> <p>Now running <code>./foo</code> should invoke <code>foo()</code> as defined in Codon, with an argument of <code>10</code>.</p> <p>Note that if the generated shared library is in a non-standard path, you can either:</p> <ul> <li>Add the <code>rpath</code> to the <code>gcc</code> command: <code>-Wl,-rpath=/path/to/lib/dir</code></li> <li>Add the library path to <code>LD_LIBRARY_PATH</code> (or <code>DYLD_LIBRARY_PATH</code> if   using macOS): <code>export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/path/to/lib/dir</code>.</li> </ul>"},{"location":"interop/cpp/#converting-types","title":"Converting types","text":"<p>The following table shows the conversions between Codon and C/C++ types:</p> Codon C/C++ <code>int</code> <code>long</code> or <code>int64_t</code> <code>float</code> <code>double</code> <code>bool</code> <code>bool</code> <code>byte</code> <code>char</code> or <code>int8_t</code> <code>str</code> <code>{int64_t, char*}</code> (length and data) <code>tuple</code> Struct of fields <code>class</code> Pointer to corresponding tuple"},{"location":"interop/decorator/","title":"Python decorator","text":""},{"location":"interop/decorator/#summary","title":"Summary","text":"<p>Codon includes a Python package called <code>codon</code> that allows functions or methods within Python codebases to be compiled and executed by Codon's JIT. The <code>codon</code> library can be installed with <code>pip</code>:</p> <pre><code>pip install codon-jit\n</code></pre> <p>This library will attempt to use an installed version of Codon. If Codon is installed at a non-standard path, set the <code>CODON_DIR</code> environment variable to the installation path.</p>"},{"location":"interop/decorator/#using-codonjit","title":"Using <code>@codon.jit</code>","text":"<p>The <code>@codon.jit</code> decorator causes the annotated function to be compiled by Codon, and automatically converts standard Python objects to native Codon objects. For example:</p> <pre><code>import codon\nfrom time import time\n\ndef is_prime_python(n):\n    if n &lt;= 1:\n        return False\n    for i in range(2, n):\n        if n % i == 0:\n            return False\n    return True\n\n@codon.jit\ndef is_prime_codon(n):\n    if n &lt;= 1:\n        return False\n    for i in range(2, n):\n        if n % i == 0:\n            return False\n    return True\n\nt0 = time()\nans = sum(1 for i in range(100000, 200000) if is_prime_python(i))\nt1 = time()\nprint(f'[python] {ans} | took {t1 - t0} seconds')\n\nt0 = time()\nans = sum(1 for i in range(100000, 200000) if is_prime_codon(i))\nt1 = time()\nprint(f'[codon]  {ans} | took {t1 - t0} seconds')\n</code></pre> <p>outputs:</p> <pre><code>[python] 8392 | took 39.6610209941864 seconds\n[codon]  8392 | took 0.998633861541748 seconds\n</code></pre> <p>\u2139\ufe0f Info: <code>@par</code> (to parallelize <code>for</code>-loops) can be used in annotated functions via a leading underscore: <code>_@par</code>.</p> <p>\u26a0\ufe0f Warning: Changes made to objects in a JIT'd function will not be reflected in the host Python application, since objects passed to Codon are converted to Codon-native types. If objects need to be modified, consider returning any necessary values and performing modifications in Python.</p> <p>\u26a0\ufe0f Warning: Polymorphism and inheritance are not yet supported in JIT mode.</p>"},{"location":"interop/decorator/#type-conversions","title":"Type conversions","text":"<p><code>@codon.jit</code> will attempt to convert any Python types that it can to native Codon types. The current conversion rules are as follows:</p> <ul> <li> <p>Basic types like <code>int</code>, <code>float</code>, <code>bool</code>, <code>str</code> and <code>complex</code> are   converted to the same type in Codon.</p> </li> <li> <p>Tuples are converted to Codon tuples (which are then compiled   down to the equivalent of C structs).</p> </li> <li> <p>Collection types like <code>list</code>, <code>dict</code> and <code>set</code> are converted to   the corresponding Codon collection type, with the restriction   that all elements in the collection must have the same type.</p> </li> <li> <p>Other types are passed to Codon directly as Python objects.   Codon will then use its Python object API (\"<code>pyobj</code>\") to handle   and operate on these objects. Internally, this consists of calling   the appropriate CPython C API functions, e.g. <code>PyNumber_Add(a, b)</code>   for <code>a + b</code>.</p> </li> </ul>"},{"location":"interop/decorator/#custom-types","title":"Custom types","text":"<p>User-defined classes can be converted to Codon classes via <code>@codon.convert</code>:</p> <pre><code>import codon\n\n@codon.convert\nclass Foo:\n    __slots__ = 'a', 'b', 'c'\n\n    def __init__(self, n):\n        self.a = n\n        self.b = n**2\n        self.c = n**3\n\n    @codon.jit\n    def total(self):\n        return self.a + self.b + self.c\n\nprint(Foo(10).total())  # 1110\n</code></pre> <p><code>@codon.convert</code> requires the annotated class to specify <code>__slots__</code>, which it uses to construct a generic Codon class (specifically, a named tuple) to store the class's converted fields.</p>"},{"location":"interop/decorator/#passing-globals-to-codon","title":"Passing globals to Codon","text":"<p>Global variables, functions or modules can be passed to JIT'd functions through the <code>pyvars</code> argument to <code>@codon.jit</code>:</p> <pre><code>import codon\n\ndef foo(n):\n    print(f'n is {n}')\n\n@codon.jit(pyvars=['foo'])\ndef bar(n):\n    foo(n)  # calls the Python function 'foo'\n    return n ** 2\n\nprint(bar(9))  # 'n is 9' then '81'\n</code></pre> <p>This also allows imported Python modules to be accessed by Codon. All <code>pyvars</code> are passed as Python objects. Note that JIT'd functions can call each other by default.</p> <p>\u2139\ufe0f Info: <code>pyvars</code> takes in variable names as strings, not the variables themselves.</p>"},{"location":"interop/decorator/#debugging","title":"Debugging","text":"<p><code>@codon.jit</code> takes an optional <code>debug</code> parameter that can be used to print debug information such as generated Codon functions and data types:</p> <pre><code>import codon\n\n@codon.jit(debug=True)\ndef sum_of_squares(v):\n    return sum(i**2 for i in v)\n\nprint(sum_of_squares([1.4, 2.9, 3.14]))\n</code></pre> <p>outputs:</p> <pre><code>[codon::jit::execute] code:\ndef sum_of_squares(v):\n    return sum(i**2 for i in v)\n-----\n[python] sum_of_squares(['List[float]'])\n[codon::jit::executePython] wrapper:\n@export\ndef __codon_wrapped__sum_of_squares_0(args: cobj) -&gt; cobj:\n    a0 = List[float].__from_py__(PyTuple_GetItem(args, 0))\n    return sum_of_squares(a0).__to_py__()\n-----\n20.229599999999998\n</code></pre>"},{"location":"interop/decorator/#internals-and-performance-tips","title":"Internals and performance tips","text":"<p>Under the hood, the <code>codon</code> module maintains an instance of the Codon JIT, which it uses to dynamically compile annotated Python functions. These functions are then wrapped in another generated function that performs the type conversions. The JIT maintains a cache of native function pointers corresponding to annotated Python functions with concrete input types. Hence, calling a JIT'd function multiple times does not repeatedly invoke the entire Codon compiler pipeline, but instead reuses the cached function pointer.</p> <p>Although object conversions from Python to Codon are generally cheap, they do impose a small overhead, meaning <code>@codon.jit</code> will work best on expensive and/or long-running operations rather than short-lived operations. By the same token, the more work can be done in Codon, the better, as opposed to repeatedly transferring back and forth.</p>"},{"location":"interop/jupyter/","title":"Jupyter integration","text":""},{"location":"interop/jupyter/#summary","title":"Summary","text":"<p>Codon ships with a kernel that can be used by Jupyter, invoked with the <code>codon jupyter ...</code> subcommand.</p> <p>To add the Codon kernel, add the following <code>kernel.json</code> file to the directory <code>/path/to/jupyter/kernels/codon/</code>:</p> <pre><code>{\n    \"display_name\": \"Codon\",\n    \"argv\": [\n        \"/path/to/codon\",\n        \"jupyter\",\n        \"{connection_file}\"\n    ],\n    \"language\": \"python\"\n}\n</code></pre>"},{"location":"interop/jupyter/#plugins","title":"Plugins","text":"<p>Plugins can also optionally be specified, as in:</p> <pre><code>{\n    \"display_name\": \"Codon\",\n    \"argv\": [\n        \"/path/to/codon\",\n        \"jupyter\",\n        \"-plugin\", \"/path/to/plugin\",\n        \"{connection_file}\"\n    ],\n    \"language\": \"python\"\n}\n</code></pre>"},{"location":"interop/numpy/","title":"NumPy support","text":""},{"location":"interop/numpy/#summary","title":"Summary","text":"<p>Codon ships with a feature-complete, fully-compiled native NumPy implementation. It uses the same API as NumPy, but re-implements everything in Codon itself, allowing for a range of optimizations and performance improvements. Codon-NumPy works with Codon's Python interoperability (you can transfer arrays to and from regular Python seamlessly), parallel backend (you can do array operations in parallel), and GPU backend (you can transfer arrays to and from the GPU seamlessly, and operate on them on the GPU).</p>"},{"location":"interop/numpy/#getting-started","title":"Getting started","text":"<p>Importing <code>numpy</code> in Codon will use Codon-NumPy (as opposed to <code>from python import numpy</code>, which would use standard NumPy):</p> <pre><code>import numpy as np\n</code></pre> <p>We can then create and manipulate arrays just like in standard NumPy:</p> <pre><code>x = np.arange(15, dtype=np.int64).reshape(3, 5)\nprint(x)\n#   0   1   2   3   4\n#   5   6   7   8   9\n#  10  11  12  13  14\n\nx[1:, ::2] = -99\n#   0   1   2   3   4\n# -99   6 -99   8 -99\n# -99  11 -99  13 -99\n\ny = x.max(axis=1)\nprint(y)\n#   4   8  13\n</code></pre> <p>In Codon-NumPy, any Codon type can be used as the array type. The <code>numpy</code> module has the same aliases that regular NumPy has, like <code>np.int64</code>, <code>np.float32</code> etc., but these simply refer to the regular Codon types.</p> <p>\u26a0\ufe0f Warning: Using a string (e.g. <code>\"i4\"</code> or <code>\"f8\"</code>) for the dtype is not yet supported.</p>"},{"location":"interop/numpy/#codon-array-type","title":"Codon array type","text":"<p>The Codon array type is parameterized by the array data type (\"<code>dtype</code>\") and the array dimension (\"<code>ndim</code>\"). That means that, in Codon-NumPy, the array dimension is a property of the type, so a 1-d array is a different type than a 2-d array and so on:</p> <pre><code>import numpy as np\n\narr = np.array([[1.1, 2.2], [3.3, 4.4]])\nprint(arr.__class__.__name__)  # ndarray[float,2]\n\narr = np.arange(10)\nprint(arr.__class__.__name__)  # ndarray[int,1]\n</code></pre> <p>The array dimension must also be known at compile-time. This allows the compiler to perform a wider range of optimizations on array operations. Usually, this has no impact on the code as the NumPy functions can determine input and output dimensions automatically. However, the dimension (and dtype) must be given when, for instance, reading arrays from disk:</p> <pre><code># 'dtype' argument specifies array type\n# 'ndim' argument specifies array dimension\narr = np.load('arr.npy', dtype=float, ndim=3)\n</code></pre> <p>A very limited number of NumPy functions return an array whose dimension cannot be deduced from its inputs. One such example is <code>squeeze()</code>, which removes axes of length 1; since the number of axes of length 1 is not determinable at compile-time, this function requires an extra argument that indicates which axes to remove.</p>"},{"location":"interop/numpy/#python-interoperability","title":"Python interoperability","text":"<p>Codon's <code>ndarray</code> type supports Codon's standard Python interoperability API (i.e. <code>__to_py__</code> and <code>__from_py__</code> methods), so arrays can be transferred to and from Python seamlessly.</p>"},{"location":"interop/numpy/#pytorch-integration","title":"PyTorch integration","text":"<p>Because PyTorch tensors and NumPy arrays are interchangeable without copying data, it is easy to use Codon to efficiently manipulate or operate on PyTorch tensors. This can be achieved either via Codon's just-in-time (JIT) compilation mode or via its Python extension mode.</p>"},{"location":"interop/numpy/#using-codon-jit","title":"Using Codon JIT","text":"<p>Here is an example showing initializing a \\(\\(128 \\times 128 \\times 128\\)\\) tensor \\(\\(A\\)\\) such that \\(\\(A_{i,j,k} = i + j + k\\)\\):</p> <pre><code>import numpy as np\nimport time\nimport codon\nimport torch\n\n@codon.jit\ndef initialize(arr):\n    for i in range(128):\n        for j in range(128):\n            for k in range(128):\n                arr[i, j, k] = i + j + k\n\n# first call JIT-compiles; subsequent calls use cached JIT'd code\ntensor = torch.empty(128, 128, 128)\ninitialize(tensor.numpy())\n\ntensor = torch.empty(128, 128, 128)\nt0 = time.time()\ninitialize(tensor.numpy())\nt1 = time.time()\n\nprint(tensor)\nprint(t1 - t0, 'seconds')\n</code></pre> <p>Timings on an M1 MacBook Pro:</p> <ul> <li>Without <code>@codon.jit</code>: 0.1645 seconds</li> <li>With <code>@codon.jit</code>: 0.001485 seconds (110x speedup)</li> </ul> <p>For more information, see the Codon JIT docs.</p>"},{"location":"interop/numpy/#using-codon-python-extensions","title":"Using Codon Python extensions","text":"<p>Codon can compile directly to a Python extension module, similar to writing a C extension for CPython or using Cython.</p> <p>Taking the same example, we can create a file <code>init.py</code>:</p> <pre><code>import numpy as np\nimport numpy.pybridge\n\ndef initialize(arr: np.ndarray[np.float32, 3]):\n    for i in range(128):\n        for j in range(128):\n            for k in range(128):\n                arr[i, j, k] = i + j + k\n</code></pre> <p>Note that extension module functions need to specify argument types. In this case, the argument is a 3-dimensional array of type <code>float32</code>, which is expressed as <code>np.ndarray[np.float32, 3]</code> in Codon.</p> <p>Now we can use a setup script <code>setup.py</code> to create the extension module as described in the Codon Python extension docs:</p> <pre><code>python3 setup.py build_ext --inplace  # setup.py from docs linked above\n</code></pre> <p>Finally, we can call the function from Python:</p> <pre><code>from codon_initialize import initialize\nimport torch\n\ntensor = torch.empty(128, 128, 128)\ninitialize(tensor.numpy())\nprint(tensor)\n</code></pre> <p>Note that there is no compilation happening at runtime with this approach. Instead, everything is compiled ahead of time when creating the extension. The timing is the same as the first approach.</p> <p>You can also use any Codon compilation flags with this approach by adding them to the <code>spawn</code> call in the setup script. For example, you can use the <code>-disable-exceptions</code> flag to disable runtime exceptions, which can yield performance improvements and generate more streamlined code.</p>"},{"location":"interop/numpy/#parallel-processing","title":"Parallel processing","text":"<p>Unlike Python, Codon has no global interpreter lock (\"GIL\") and supports full multithreading, meaning NumPy code can be parallelized. For example:</p> <pre><code>import numpy as np\nimport numpy.random as rnd\nimport time\n\nN = 100000000\nn = 10\n\nrng = rnd.default_rng(seed=0)\nx = rng.normal(size=(N,n))\ny = np.empty(n)\n\nt0 = time.time()\n\n@par(num_threads=n)\nfor i in range(n):\n    y[i] = x[:,i].sum()\n\nt1 = time.time()\n\nprint(y)\nprint(t1 - t0, 'seconds')\n# no par - 1.4s\n# w/ par - 0.4s\n</code></pre>"},{"location":"interop/numpy/#gpu-processing","title":"GPU processing","text":"<p>Codon-NumPy supports seamless GPU processing: arrays can be passed to and from the GPU, and array operations can be performed on the GPU using Codon's GPU backend. Here's an example that computes the Mandelbrot set:</p> <pre><code>import numpy as np\nimport gpu\n\nMAX    = 1000  # maximum Mandelbrot iterations\nN      = 4096  # width and height of image\npixels = np.empty((N, N), int)\n\ndef scale(x, a, b):\n    return a + (x/N)*(b - a)\n\n@gpu.kernel\ndef mandelbrot(pixels):\n    i = (gpu.block.x * gpu.block.dim.x) + gpu.thread.x\n    j = (gpu.block.y * gpu.block.dim.y) + gpu.thread.y\n    c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))\n    z = 0j\n    iteration = 0\n\n    while abs(z) &lt;= 2 and iteration &lt; MAX:\n        z = z**2 + c\n        iteration += 1\n\n    pixels[i, j] = 255 * iteration/MAX\n\nmandelbrot(pixels, grid=(N//32, N//32), block=(32, 32))\n</code></pre> <p>Here is the same code using GPU-parallelized <code>for</code>-loops:</p> <pre><code>import numpy as np\nimport gpu\n\nMAX    = 1000  # maximum Mandelbrot iterations\nN      = 4096  # width and height of image\npixels = np.empty((N, N), int)\n\ndef scale(x, a, b):\n    return a + (x/N)*(b - a)\n\n@par(gpu=True, collapse=2)  # &lt;--\nfor i in range(N):\n    for j in range(N):\n        c = complex(scale(j, -2.00, 0.47), scale(i, -1.12, 1.12))\n        z = 0j\n        iteration = 0\n\n        while abs(z) &lt;= 2 and iteration &lt; MAX:\n            z = z**2 + c\n            iteration += 1\n\n        pixels[i, j] = 255 * iteration/MAX\n</code></pre>"},{"location":"interop/numpy/#linear-algebra","title":"Linear algebra","text":"<p>Codon-NumPy fully supports the NumPy linear algebra module which provides a comprehensive set of functions for linear algebra operations. Importing the linear algebra module, just like in standard NumPy:</p> <pre><code>import numpy.linalg as LA\n</code></pre> <p>For example, the <code>eig()</code> function computes the eigenvalues and eigenvectors of a square matrix:</p> <pre><code>eigenvalues, eigenvectors = LA.eig(np.diag((1, 2, 3)))\nprint(eigenvalues)\n# 1.+0.j 2.+0.j 3.+0.j\n\nprint(eigenvectors)\n# [[1.+0.j 0.+0.j 0.+0.j]\n#  [0.+0.j 1.+0.j 0.+0.j]\n#  [0.+0.j 0.+0.j 1.+0.j]]\n</code></pre> <p>Just like standard NumPy, Codon will use an optimized BLAS library under the hood to implement many linear algebra operations. This defaults to OpenBLAS on Linux and Apple's Accelerate framework on macOS.</p> <p>Because Codon supports full multithreading, it's possible to use outer-loop parallelism to perform linear algebra operations in parallel. Here's an example that multiplies several matrices in parallel:</p> <pre><code>import numpy as np\nimport numpy.random as rnd\nimport time\n\nN = 5000\nn = 10\nrng = rnd.default_rng(seed=0)\na = rng.normal(size=(n, N, N))\nb = rng.normal(size=(n, N, N))\ny = np.empty((n, N, N))\nt0 = time.time()\n\n@par(num_threads=n)\nfor i in range(n):\n    y[i, :, :] = a[i, :, :] @ b[i, :, :]\n\nt1 = time.time()\nprint(y.sum())\nprint(t1 - t0, 'seconds')  # Python - 53s\n                           # Codon  -  6s\n</code></pre> <p>\u26a0\ufe0f Warning: When using Codon's outer-loop parallelism, make sure to set the environment variable <code>OPENBLAS_NUM_THREADS</code> to 1 (i.e. <code>export OPENBLAS_NUM_THREADS=1</code>) to avoid conflicts with OpenBLAS multithreading.</p>"},{"location":"interop/numpy/#numpy-specific-compiler-optimizations","title":"NumPy-specific compiler optimizations","text":"<p>Codon includes compiler passes that optimize NumPy code through methods like operator fusion, which combine distinct operations so that they can be executed during a single pass through the argument arrays, saving both execution time and memory (since intermediate arrays no longer need to be allocated).</p> <p>To showcase this, here's a simple NumPy program that approximates \\(\\(\\pi\\)\\). The code below generates two random vectors \\(\\(x\\)\\) and \\(\\(y\\)\\) with entries in the range \\(\\([0, 1)\\)\\) and computes the fraction of pairs of points that lie in the circle of radius \\(\\(0.5\\)\\) centered at \\(\\((0.5, 0.5)\\)\\), which is approximately \\(\\(\\pi \\over 4\\)\\).</p> <pre><code>import time\nimport numpy as np\n\nrng = np.random.default_rng(seed=0)\nx = rng.random(500_000_000)\ny = rng.random(500_000_000)\n\nt0 = time.time()\n# pi ~= 4 x (fraction of points in circle)\npi = ((x-1)**2 + (y-1)**2 &lt; 1).sum() * (4 / len(x))\nt1 = time.time()\n\nprint(pi)\nprint(t1 - t0, 'seconds')\n</code></pre> <p>The expression <code>(x-1)**2 + (y-1)**2 &lt; 1</code> gets fused by Codon so that it is executed in just a single pass over the <code>x</code> and <code>y</code> arrays, rather than in multiple passes for each sub-expression <code>x-1</code>, <code>y-1</code> etc. as is the case with standard NumPy.</p> <p>Here are the resulting timings on an M1 MacBook Pro:</p> <ul> <li>Python / standard NumPy: 2.4 seconds</li> <li>Codon: 0.42 seconds (6x speedup)</li> </ul> <p>You can display information about fused expressions by using the <code>-npfuse-verbose</code> flag of <code>codon</code>, as in <code>codon run -release -npfuse-verbose pi.py</code>. Here's the output for the program above:</p> <pre><code>Optimizing expression at pi.py:10:7\nlt &lt;array[bool, 1]&gt; [cost=6]\n  add &lt;array[f64, 1]&gt; [cost=5]\n    pow &lt;array[f64, 1]&gt; [cost=2]\n      sub &lt;array[f64, 1]&gt; [cost=1]\n        a0 &lt;array[f64, 1]&gt;\n        a1 &lt;i64&gt;\n      a2 &lt;i64&gt;\n    pow &lt;array[f64, 1]&gt; [cost=2]\n      sub &lt;array[f64, 1]&gt; [cost=1]\n        a3 &lt;array[f64, 1]&gt;\n        a4 &lt;i64&gt;\n      a5 &lt;i64&gt;\n  a6 &lt;i64&gt;\n\n-&gt; static fuse:\nlt &lt;array[bool, 1]&gt; [cost=6]\n  add &lt;array[f64, 1]&gt; [cost=5]\n    pow &lt;array[f64, 1]&gt; [cost=2]\n      sub &lt;array[f64, 1]&gt; [cost=1]\n        a0 &lt;array[f64, 1]&gt;\n        a1 &lt;i64&gt;\n      a2 &lt;i64&gt;\n    pow &lt;array[f64, 1]&gt; [cost=2]\n      sub &lt;array[f64, 1]&gt; [cost=1]\n        a3 &lt;array[f64, 1]&gt;\n        a4 &lt;i64&gt;\n      a5 &lt;i64&gt;\n  a6 &lt;i64&gt;\n</code></pre> <p>As shown, the optimization pass employs a cost model to decide how to best handle a given expression, be it by fusing or evaluating sequentially. You can adjust the fusion cost thresholds via the following flags:</p> <ul> <li><code>-npfuse-always &lt;cost1&gt;</code>: Expression cost below which to always fuse a given   expression (default: <code>10</code>).</li> <li><code>-npfuse-never &lt;cost2&gt;</code>: Expression cost above which (&gt;) to never fuse a given   expression (default: <code>50</code>).</li> </ul> <p>Given an expression cost <code>C</code>, the logic implemented in the pass is to:</p> <ul> <li>Always fuse expressions where <code>C &lt;= cost1</code>.</li> <li>Fuse expressions where <code>cost1 &lt; C &lt;= cost2</code> if there is no broadcasting involved.</li> <li>Never fuse expressions where <code>C &gt; cost2</code> and instead evaluate them sequentially.</li> </ul> <p>This logic is applied recursively to a given expression to determine the optimal evaluation strategy.</p> <p>You can disable these optimizations altogether by disabling the corresponding compiler pass via the flag <code>-disable-opt core-numpy-fusion</code>.</p>"},{"location":"interop/numpy/#io","title":"I/O","text":"<p>Codon-NumPy supports most of NumPy's I/O API. One important difference, however, is that I/O functions must specify the dtype and dimension of arrays being read, since Codon-NumPy array types are parameterized by dtype and dimension:</p> <pre><code>import numpy as np\n\na = np.arange(27, dtype=np.int16).reshape(3, 3, 3)\nnp.save('arr.npy', a)\n\n# Notice the 'dtype' and 'ndim' arguments:\nb = np.load('arr.npy', dtype=np.int16, ndim=3)\n</code></pre> <p>Writing arrays has no such requirement.</p>"},{"location":"interop/numpy/#datetimes","title":"Datetimes","text":"<p>Codon-NumPy fully supports NumPy's datetime types: <code>datetime64</code> and <code>timedelta64</code>. One difference from standard NumPy is how these types are specified. Here's an example:</p> <pre><code># datetime64 type with units of \"1 day\"\n# same as \"dtype='datetime64[D]'\" in standard NumPy\ndt = np.array(['2020-01-02', '2021-09-15', '2022-07-01'],\n              dtype=np.datetime64['D', 1])\n\n# timedelta64 type with units of \"15 minutes\"\n# same as \"dtype='timedelta64[15m]'\" in standard NumPy\ntd = np.array([100, 200, 300], dtype=np.timedelta64['m', 15])\n</code></pre>"},{"location":"interop/numpy/#passing-array-data-to-cc","title":"Passing array data to C/C++","text":"<p>You can pass an <code>ndarray</code>'s underlying data pointer to a C/C++ function by using the <code>data</code> attribute of the array. For example:</p> <pre><code>from C import foo(p: Ptr[float], n: int)\n\narr = np.ndarray([1.0, 2.0, 3.0])\nfoo(arr.data, arr.size)\n</code></pre> <p>Of course, it's the caller's responsibility to make sure the array is contiguous as needed and/or pass additional shape or stride information. See the C interoperability docs for more information.</p>"},{"location":"interop/numpy/#array-abi","title":"Array ABI","text":"<p>The <code>ndarray[dtype, ndim]</code> data structure has three fields, in the following order:</p> <ul> <li><code>shape</code>: length-<code>ndim</code> tuple of non-negative 64-bit integers representing the array   shape</li> <li><code>strides</code>: length-<code>ndim</code> tuple of 64-bit integers representing the stride in bytes   along each axis of the array</li> <li><code>data</code>: pointer of type <code>dtype</code> to the array's data</li> </ul> <p>For example, <code>ndarray[np.float32, 3]</code> would correspond to the following C structure:</p> <pre><code>struct ndarray_float32_3 {\n  int64_t shape[3];\n  int64_t strides[3];\n  float *data;\n};\n</code></pre> <p>This can be used to pass an entire <code>ndarray</code> object to a C function without breaking it up into its constituent components.</p>"},{"location":"interop/numpy/#performance-tips","title":"Performance tips","text":""},{"location":"interop/numpy/#array-layouts","title":"Array layouts","text":"<p>As with standard NumPy, Codon-NumPy performs best when array data is contiguous in memory, ideally in row-major order (also called \"C order\"). Most NumPy functions will return C-order arrays, but operations like slicing and transposing arrays can alter contiguity. You can use <code>numpy.ascontiguousarray()</code> to create a contiguous array from an arbitrary array.</p>"},{"location":"interop/numpy/#linux-huge-pages","title":"Linux huge pages","text":"<p>When working with large arrays on Linux, enabling transparent hugepages can result in significant performance improvements.</p> <p>You can check if transparent hugepages are enabled via</p> <pre><code>cat /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre> <p>and you can enable them via</p> <pre><code>echo \"always\" | sudo tee /sys/kernel/mm/transparent_hugepage/enabled\n</code></pre>"},{"location":"interop/numpy/#disabling-exceptions","title":"Disabling exceptions","text":"<p>By default, Codon performs various validation checks at runtime (e.g. bounds checks when indexing an array) just like standard NumPy, and raises an exception if they fail. If you know your program will not raise or catch any exceptions, you can disable these checks through the <code>-disable-exceptions</code> compiler flag.</p> <p>Note that when using this flag, raising an exception will terminate the process with a <code>SIGTRAP</code>.</p>"},{"location":"interop/numpy/#fast-math","title":"Fast-math","text":"<p>You can enable \"fast-math\" optimizations via the <code>-fast-math</code> compiler flag. It is advisable to use this flag with caution as it changes floating point semantics and makes assumptions regarding <code>inf</code> and <code>nan</code> values. For more information, consult LLVM's documentation on fast-math flags.</p>"},{"location":"interop/numpy/#not-yet-supported","title":"Not-yet-supported","text":"<p>The following features of NumPy are not yet supported, but are planned for the future: - String operations - Masked arrays - Polynomials</p> <p>A few miscellaneous Python-specific functions like <code>get_include()</code> are also not supported, as they are not applicable in Codon.</p>"},{"location":"interop/pyext/","title":"Python extensions","text":""},{"location":"interop/pyext/#summary","title":"Summary","text":"<p>Codon includes a build mode called <code>pyext</code> for generating Python extensions (which are traditionally written in C, C++ or Cython):</p> <pre><code>codon build -pyext extension.codon  # add -release to enable optimizations\n</code></pre> <p><code>codon build -pyext</code> accepts the following options:</p> <ul> <li><code>-o &lt;output object&gt;</code>: Writes the compilation result to the specified file.</li> <li><code>-module &lt;module name&gt;</code>: Specifies the generated Python module's name.</li> </ul> <p>\u26a0\ufe0f Warning: It is recommended to use the <code>pyext</code> build mode with Python versions 3.9 and up.</p>"},{"location":"interop/pyext/#functions","title":"Functions","text":"<p>Extension functions written in Codon should generally be fully typed:</p> <pre><code>def foo(a: int, b: float, c: str):  # return type will be deduced\n    return a * b + float(c)\n</code></pre> <p>The <code>pyext</code> build mode will automatically generate all the necessary wrappers and hooks for converting a function written in Codon into a function that's callable from Python.</p> <p>Function arguments that are not explicitly typed will be treated as generic Python objects, and operated on through the CPython API.</p> <p>Function overloads are also possible in Codon:</p> <pre><code>def bar(x: int):\n    return x + 2\n\n@overload\ndef bar(x: str):\n    return x * 2\n</code></pre> <p>This will result in a single Python function <code>bar()</code> that dispatches to the correct Codon <code>bar()</code> at runtime based on the argument's type (or raise a <code>TypeError</code> on an invalid input type).</p>"},{"location":"interop/pyext/#types","title":"Types","text":"<p>Codon class definitions can also be converted to Python extension types via the <code>@dataclass(python=True)</code> decorator:</p> <pre><code>@dataclass(python=True)\nclass Vec:\n    x: float\n    y: float\n\n    def __init__(self, x: float = 0.0, y: float = 0.0):\n        self.x = x\n        self.y = y\n\n    def __add__(self, other: Vec):\n        return Vec(self.x + other.x, self.y + other.y)\n\n    def __add__(self, other: float):\n        return Vec(self.x + other, self.y + other)\n\n    def __repr__(self):\n        return f'Vec({self.x}, {self.y})'\n</code></pre> <p>Now in Python (assuming we compile to a module <code>vec</code>):</p> <pre><code>from vec import Vec\n\na = Vec(x=3.0, y=4.0)  # Vec(3.0, 4.0)\nb = a + Vec(1, 2)      # Vec(4.0, 6.0)\nc = b + 10.0           # Vec(14.0, 16.0)\n</code></pre>"},{"location":"interop/pyext/#building-with-setuptools","title":"Building with <code>setuptools</code>","text":"<p>Codon's <code>pyext</code> build mode can be used with <code>setuptools</code>. Here is a minimal example:</p> <pre><code># setup.py\nimport os\nimport sys\nimport shutil\nfrom pathlib import Path\nfrom setuptools import setup, Extension\nfrom setuptools.command.build_ext import build_ext\n\n# Find Codon\ncodon_path = os.environ.get('CODON_DIR')\nif not codon_path:\n    c = shutil.which('codon')\n    if c:\n        codon_path = Path(c).parent / '..'\nelse:\n    codon_path = Path(codon_path)\nfor path in [\n    os.path.expanduser('~') + '/.codon',\n    os.getcwd() + '/..',\n]:\n    path = Path(path)\n    if not codon_path and path.exists():\n        codon_path = path\n        break\n\nif (\n    not codon_path\n    or not (codon_path / 'include' / 'codon').exists()\n    or not (codon_path / 'lib' / 'codon').exists()\n):\n    print(\n        'Cannot find Codon.',\n        'Please either install Codon (https://github.com/exaloop/codon),',\n        'or set CODON_DIR if Codon is not in PATH.',\n        file=sys.stderr,\n    )\n    sys.exit(1)\ncodon_path = codon_path.resolve()\nprint('Found Codon:', str(codon_path))\n\n# Build with Codon\nclass CodonExtension(Extension):\n    def __init__(self, name, source):\n        self.source = source\n        super().__init__(name, sources=[], language='c')\n\nclass BuildCodonExt(build_ext):\n    def build_extensions(self):\n        pass\n\n    def run(self):\n        inplace, self.inplace = self.inplace, False\n        super().run()\n        for ext in self.extensions:\n            self.build_codon(ext)\n        if inplace:\n            self.copy_extensions_to_source()\n\n    def build_codon(self, ext):\n        extension_path = Path(self.get_ext_fullpath(ext.name))\n        build_dir = Path(self.build_temp)\n        os.makedirs(build_dir, exist_ok=True)\n        os.makedirs(extension_path.parent.absolute(), exist_ok=True)\n\n        codon_cmd = str(codon_path / 'bin' / 'codon')\n        optimization = '-debug' if self.debug else '-release'\n        self.spawn([codon_cmd, 'build', optimization, '--relocation-model=pic', '-pyext',\n                    '-o', str(extension_path) + \".o\", '-module', ext.name, ext.source])\n\n        ext.runtime_library_dirs = [str(codon_path / 'lib' / 'codon')]\n        self.compiler.link_shared_object(\n            [str(extension_path) + '.o'],\n            str(extension_path),\n            libraries=['codonrt'],\n            library_dirs=ext.runtime_library_dirs,\n            runtime_library_dirs=ext.runtime_library_dirs,\n            extra_preargs=['-Wl,-rpath,@loader_path'],\n            debug=self.debug,\n            build_temp=self.build_temp,\n        )\n        self.distribution.codon_lib = extension_path\n\nsetup(\n    name='mymodule',\n    version='0.1',\n    packages=['mymodule'],\n    ext_modules=[\n        CodonExtension('mymodule', 'mymodule.codon'),\n    ],\n    cmdclass={'build_ext': BuildCodonExt}\n)\n</code></pre> <p>Then, for example, we can build with:</p> <pre><code>python3 setup.py build_ext --inplace\n</code></pre> <p>Finally, we can <code>import mymodule</code> in Python and use the module.</p>"},{"location":"interop/python/","title":"Python integration","text":""},{"location":"interop/python/#summary","title":"Summary","text":"<p>Calling Python from Codon is possible in two ways:</p> <ul> <li><code>from python import</code> allows importing and calling Python functions     from existing Python modules.</li> <li><code>@python</code> allows writing Python code directly in Codon.</li> </ul> <p>In order to use these features, the <code>CODON_PYTHON</code> environment variable must be set to the appropriate Python shared library:</p> <pre><code>export CODON_PYTHON=/path/to/libpython.X.Y.so\n</code></pre> <p>For example, with a <code>brew</code>-installed Python 3.9 on macOS, this might be</p> <pre><code>/usr/local/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/libpython3.9.dylib\n</code></pre> <p>Note that only Python versions 3.6 and later are supported.</p>"},{"location":"interop/python/#from-python-import","title":"<code>from python import</code>","text":"<p>Let\\'s say we have a Python function defined in mymodule.py:</p> <pre><code>def multiply(a, b):\n    return a * b\n</code></pre> <p>We can call this function in Codon using <code>from python import</code> and indicating the appropriate call and return types:</p> <pre><code>from python import mymodule.multiply(int, int) -&gt; int\nprint(multiply(3, 4))  # 12\n</code></pre> <p>(Be sure the <code>PYTHONPATH</code> environment variable includes the path of mymodule.py!)</p> <p><code>from python import</code> does not need to specify explicit types, in which case Codon will operate directly on the Python objects, and convert Codon types to Python types as necessary:</p> <pre><code>from python import numpy as np  # Codon will call NumPy through CPython's API\nx = np.array([1, 2, 3, 4]) * 10\nprint(x)  # [10 20 30 40]\n</code></pre>"},{"location":"interop/python/#python","title":"<code>@python</code>","text":"<p>Codon programs can contain functions that will be executed by Python via <code>pydef</code>:</p> <pre><code>@python\ndef multiply(a: int, b: int) -&gt; int:\n    return a * b\n\nprint(multiply(3, 4))  # 12\n</code></pre> <p>This makes calling Python modules like NumPy very easy:</p> <pre><code>@python\ndef myrange(n: int) -&gt; List[int]:\n    from numpy import arange\n    return list(arange(n))\n\nprint(myrange(5))  # [0, 1, 2, 3, 4]\n</code></pre>"},{"location":"interop/python/#data-conversions","title":"Data conversions","text":"<p>Codon uses two new magic methods to transfer data to and from Python:</p> <ul> <li><code>__to_py__</code>: Produces a Python object (<code>PyObject*</code> in C) given a Codon object.</li> <li><code>__from_py__</code>: Produces a Codon object given a Python object.</li> </ul> <pre><code>import python  # needed to initialize the Python runtime\n\no = (42).__to_py__()  # type of 'o' is 'cobj', equivalent to a pointer in C\nprint(o)  # 0x100e00610\n\nn = int.__from_py__(o)\nprint(n)  # 42\n</code></pre> <p>Codon stores the results of <code>__to_py__</code> calls by wrapping them in an instance of a new class called <code>pyobj</code>, which correctly handles the underlying Python object's reference count. All operations on <code>pyobj</code>s then go through CPython's API.</p>"},{"location":"intro/differences/","title":"Differences with Python","text":""},{"location":"intro/differences/#summary","title":"Summary","text":"<p>While Codon's syntax and semantics are nearly identical to Python's, there are some notable differences that are worth mentioning. Most of these design decisions were made with the trade-off between performance and Python compatibility in mind.</p> <p>Please see our roadmap for more information about how we plan to close some of these gaps in the future.</p>"},{"location":"intro/differences/#data-types","title":"Data types","text":"<ul> <li> <p>Integers: Codon's <code>int</code> is a 64-bit signed integer,   whereas Python's (after version 3) can be arbitrarily large.   However Codon does support larger integers via <code>Int[N]</code> where   <code>N</code> is the bit width.</p> </li> <li> <p>Strings: Codon currently uses ASCII strings unlike   Python's unicode strings.</p> </li> <li> <p>Dictionaries: Codon's dictionary type does not preserve   insertion order, unlike Python's as of 3.6.</p> </li> <li> <p>Tuples: Since tuples compile down to structs, tuple lengths   must be known at compile time, meaning you can't convert an   arbitrarily-sized list to a tuple, for instance.</p> </li> </ul>"},{"location":"intro/differences/#type-checking","title":"Type checking","text":"<p>Since Codon performs static type checking ahead of time, a few of Python's dynamic features are disallowed. For example, monkey patching classes at runtime (although Codon supports a form of this at compile time) or adding objects of different types to a collection.</p> <p>These few restrictions are ultimately what allow Codon to compile to native code without any runtime performance overhead. Future versions of Codon will lift some of these restrictions by the introduction of e.g. implicit union types.</p>"},{"location":"intro/differences/#numerics","title":"Numerics","text":"<p>For performance reasons, some numeric operations use C semantics rather than Python semantics. This includes, for example, raising an exception when dividing by zero, or other checks done by <code>math</code> functions. Strict adherence to Python semantics can be achieved by using the <code>-numerics=py</code> flag of the Codon compiler. Note that this does not change <code>int</code>s from 64-bit.</p>"},{"location":"intro/differences/#modules","title":"Modules","text":"<p>While most of the commonly used builtin modules have Codon-native implementations, a few are not yet implemented. However these can still be used within Codon via <code>from python import</code>.</p>"},{"location":"intro/faq/","title":"Frequently asked questions","text":""},{"location":"intro/faq/#summary","title":"Summary","text":"<p>Here are some of the most frequently asked questions we get about Codon. We periodically update this baased on question themes we get on our Discord Server - be sure to sign up and join the community - Join here!</p>"},{"location":"intro/faq/#what-is-codon","title":"What is Codon?","text":"<p>Codon is a high-performance Python compiler that compiles Python code to native machine code without any runtime overhead. Typical speedups over Python are on the order of 10-100x or more, on a single thread. Codon's performance is typically on par with that of C/C++. Unlike Python, Codon supports native multithreading, which can lead to speedups many times higher still. Codon is extensible via a plugin infrastructure, which lets you incorporate new libraries, compiler optimizations and even keywords.</p>"},{"location":"intro/faq/#what-isnt-codon","title":"What isn't Codon?","text":"<p>While Codon supports nearly all of Python's syntax, it is not a drop-in replacement, and large codebases might require modifications to be run through the Codon compiler. For example, some of Python's modules are not yet implemented within Codon, and a few of Python's dynamic features are disallowed. The Codon compiler produces detailed error messages to help identify and resolve any incompatibilities. Codon supports seamless Python interoperability to handle cases where specific Python libraries or dynamism are required, and also supports writing Python extension modules that can be imported and used from larger Python codebases.</p>"},{"location":"intro/faq/#why-codon","title":"Why Codon?","text":"<p>Python is arguably the world's most popular programming language, and is gradually becoming the lingua franca particularly amongst non-technical or non-CS practitioners in numerous fields. It provides a readable, clean syntax, is easy to learn, and has an unmatched ecosystem of libraries. However, Python's achilles heel has always been performance: a typical codebase in pure Python is orders of magnitude slower than its C/C++/Rust counterpart.</p> <p>Codon bridges the gap between Python's simplicity and ease-of-use, and the performance of low-level languages like C++ or Rust, by using novel compiler and type checking techniques to statically compile code ahead-of-time, avoiding all of vanilla Python's runtime overhead and performance drawbacks.</p>"},{"location":"intro/faq/#how-does-codon-compare-to","title":"How does Codon compare to...","text":"<ul> <li> <p>CPython? Codon tries to follow CPython's syntax, semantics and APIs as   closely as possible, aside from a few cases where Codon differs from CPython for   performance reasons (one example being Codon's 64-bit <code>int</code> vs. CPython's arbitrary-   width <code>int</code>). Performance-wise, speedups over CPython are usually on the order of 10-100x.</p> </li> <li> <p>Numba? While Codon does offer a JIT decorator similar to Numba's, Codon is in   general an ahead-of-time compiler that compiles end-to-end programs to native code.   It also supports compilation of a much broader set of Python constructs and libraries.</p> </li> <li> <p>PyPy? PyPy strives to effectively be a drop-in replacement for CPython, whereas   Codon differs in a few places in order to eliminate any dynamic runtime or virtual   machine, and thereby attain much better performance.</p> </li> <li> <p>Cython? Like Cython, Codon has a Python-extension build mode that   compiles to Python extension modules, allowing Codon-compiled code to be imported and called   from plain Python.</p> </li> <li> <p>C++? Codon often generates the same code as an equivalent C or C++ program. Codon   can sometimes generate better code than C/C++ compilers for a variety of reasons, such   as better container implementations, the fact that Codon does not use object files and   inlines all library code, or Codon-specific compiler optimizations that are not performed   with C or C++.</p> </li> <li> <p>Julia? Codon's compilation process is actually much closer to C++ than to Julia. Julia   is a dynamically-typed language that performs type inference as an optimization, whereas   Codon type checks the entire program ahead of time. Codon also tries to circumvent the learning   curve of a new language by adopting Python's syntax and semantics.</p> </li> <li> <p>Mojo? Mojo strives to add low-level programming support/features to the Python language,   while also supporting the rest of Python by relying on CPython. By contrast, Codon aims to   make Python itself more performant by using new type checking and compilation techniques,   without trying to be a superset or drop-in replacement. Codon tries to minimize new syntax   and language features with respect to Python.</p> </li> </ul> <p>You can see results from Codon's benchmark suite suite at exaloop.io/#benchmarks. More benchmarks can be found in the 2019 paper on bioinformatics-specific use cases (note that the name used in that paper is that of Codon's predecessor, \"Seq\").</p>"},{"location":"intro/faq/#i-want-to-use-codon-but-i-have-a-large-python-codebase-i-dont-want-to-port","title":"I want to use Codon, but I have a large Python codebase I don't want to port.","text":"<p>You can use Codon on a per-function basis via the <code>@codon.jit</code> decorator, which can be used within Python codebases. This will compile only the annotated functions and automatically handle data conversions to and from Codon. It also allows for the use of any Codon-specific modules or extensions, such as multithreading.</p> <p>Codon can also compile to Python extension modules that can be imported and used from Python.</p>"},{"location":"intro/faq/#what-about-interoperability-with-other-languages-and-frameworks","title":"What about interoperability with other languages and frameworks?","text":"<p>Interoperability is and will continue to be a priority for Codon. We don't want using Codon to render you unable to use all the other great frameworks and libraries that exist. Codon supports full interoperability with Python and C/C++.</p>"},{"location":"intro/faq/#does-codon-use-garbage-collection","title":"Does Codon use garbage collection?","text":"<p>Yes, Codon uses the Boehm garbage collector.</p>"},{"location":"intro/faq/#codon-doesnt-support-python-module-x-or-function-y","title":"Codon doesn't support Python module X or function Y.","text":"<p>While Codon covers a sizeable subset of Python's standard library, it does not yet cover every function from every module. Note that missing functions can still be called through Python via <code>from python import</code>. Many of the functions that lack Codon-native implementations (e.g. I/O or OS related functions) will generally also not see substantial speedups from Codon.</p>"},{"location":"intro/faq/#codon-is-no-faster-than-python-for-my-application","title":"Codon is no faster than Python for my application.","text":"<p>Applications that spend most of their time in C-implemented library code generally do not see substantial performance improvements in Codon. Similarly, applications that are I/O or network-bound will have the same bottlenecks in Codon.</p>"},{"location":"intro/faq/#codon-is-slower-than-python-for-my-application","title":"Codon is slower than Python for my application.","text":"<p>Please report any cases where Codon is noticeably slower than Python as bugs on our issue tracker.</p>"},{"location":"intro/faq/#is-codon-free-and-open-source","title":"Is Codon free and open source?","text":"<p>Yes, Codon is free and open source under the Apache License, Version 2.0. Exaloop offers enterprise and custom solutions on top of Codon for a variety of applications, use cases and industries; please email info@exaloop.io to learn more.</p>"},{"location":"intro/faq/#contributing","title":"Contributing","text":""},{"location":"intro/faq/#does-codon-accept-outside-contributions","title":"Does Codon accept outside contributions?","text":"<p>Absolutely, we'd be delighted to accept any contributions in the form of issues, bug reports, feature requests or pull requests.</p>"},{"location":"intro/faq/#i-want-to-contribute-where-do-i-start","title":"I want to contribute. Where do I start?","text":"<p>If you have a specific feature or use case in mind, here is a quick breakdown of the codebase to help provide a sense of where to look first:</p> <ul> <li><code>codon/</code>: compiler code</li> <li><code>codon/parser/</code>:     parser and type checker code: this is the first step of compilation</li> <li><code>codon/cir/</code>:     Codon IR and optimizations: the second step of compilation</li> <li><code>codon/cir/llvm/</code>:     conversion from Codon IR to LLVM IR and machine code: the last step of compilation</li> <li><code>codon/runtime/</code>:     runtime library: used during execution</li> <li><code>stdlib/</code>: standard library code</li> </ul> <p>You can also take a look at some of the open issues. If you have any question or suggestions, please feel free to ask in the forum.</p>"},{"location":"intro/faq/#is-there-a-contributor-license-agreement-cla","title":"Is there a Contributor License Agreement (CLA)?","text":"<p>Yes, there is a CLA that is required to be agreed to before any pull requests are merged. Please see exaloop.io/legal/cla for more information. To agree to the CLA, send an email with your GitHub username to info@exaloop.io.</p>"},{"location":"intro/intro/","title":"Getting started","text":""},{"location":"intro/intro/#summary","title":"Summary","text":"<p>We give a short overview of how to get up and running using Codon.</p>"},{"location":"intro/intro/#using-codon","title":"Using <code>codon</code>","text":"<p>The <code>codon</code> program can directly <code>run</code> Codon source in JIT mode:</p> <pre><code>codon run myprogram.codon\n</code></pre> <p>The default compilation and run mode is debug (<code>-debug</code>). Compile and run with optimizations with the <code>-release</code> option:</p> <pre><code>codon run -release myprogram.codon\n</code></pre> <p><code>codon</code> can also <code>build</code> executables:</p> <pre><code># generate 'myprogram' executable\ncodon build -exe myprogram.codon\n\n# generate 'foo' executable\ncodon build -o foo myprogram.codon\n</code></pre> <p><code>codon</code> can produce object files:</p> <pre><code># generate 'myprogram.o' object file\ncodon build -obj myprogram.codon\n\n# generate 'foo.o' object file\ncodon build -o foo.o myprogram.codon\n</code></pre> <p><code>codon</code> can produce LLVM IR:</p> <pre><code># generate 'myprogram.ll' object file\ncodon build -llvm myprogram.codon\n\n# generate 'foo.ll' object file\ncodon build -o foo.ll myprogram.codon\n</code></pre>"},{"location":"intro/intro/#compile-time-definitions","title":"Compile-time definitions","text":"<p><code>codon</code> allows for compile-time definitions via the <code>-D</code> flag. For example, in the following code:</p> <pre><code>print(Int[BIT_WIDTH]())\n</code></pre> <p><code>BIT_WIDTH</code> can be specified on the command line as such: <code>codon run -DBIT_WIDTH=10 myprogram.codon</code>.</p>"},{"location":"intro/releases/","title":"Release notes","text":""},{"location":"intro/releases/#summary","title":"Summary","text":"<p>Below you can find release notes for each major Codon release, listing improvements, updates, optimizations and more for each new version.</p> <p>These release notes generally do not include small bug fixes. See the closed issues for more information.</p>"},{"location":"intro/releases/#v018","title":"v0.18","text":""},{"location":"intro/releases/#license-change","title":"License change","text":"<ul> <li>Codon is now truly open source under the Apache license.</li> <li>Exaloop continues to offer enterprise licenses with added support, services   and custom solutions for organizations that want and need them. Contact   info@exaloop.io to learn more.</li> </ul>"},{"location":"intro/releases/#new-codon-native-numpy-implementation","title":"New Codon-native NumPy implementation","text":"<ul> <li>New NumPy implementation for Codon, written in Codon itself.</li> <li>Interoperable with Codon's multithreading and GPU backends.</li> <li>NumPy-specific compiler optimizations (e.g. operator fusion optimizations)   added to Codon's standard optimization suite.</li> <li>Learn more in the Codon-NumPy docs.</li> </ul>"},{"location":"intro/releases/#new-compiler-options","title":"New compiler options","text":"<ul> <li><code>-fast-math</code> will enable fast-math optimizations.   Use this flag with caution as it changes floating-point semantics.</li> </ul>"},{"location":"intro/releases/#v017","title":"v0.17","text":""},{"location":"intro/releases/#llvm-upgrade","title":"LLVM upgrade","text":"<p>Upgraded to LLVM 17 (from 15).</p>"},{"location":"intro/releases/#standard-library-updates","title":"Standard library updates","text":"<ul> <li>New floating-point types <code>float16</code>, <code>bfloat16</code> and <code>float128</code>.</li> <li>Updates to several existing functions, such as adding <code>key</code> and   <code>default</code> arguments to <code>min()</code> and <code>max()</code>.</li> <li>Slice arguments can now be of any type, not just <code>int</code>.</li> <li>Added <code>input()</code> function.</li> </ul>"},{"location":"intro/releases/#other-improvements","title":"Other improvements","text":"<ul> <li>Property setters are now supported.</li> <li>Updated import logic to match CPython's more closely.</li> <li>Several improvements to dynamic polymorphism to match CPython more   closely.</li> </ul>"},{"location":"intro/releases/#new-compiler-options_1","title":"New compiler options","text":"<ul> <li><code>-disable-exceptions</code> will disable exceptions, potentially eliding   various runtime checks (e.g. bounds checks for lists). This flag   should only be used if you know that no exceptions will be raised   in the given program.</li> </ul>"},{"location":"intro/releases/#v016","title":"v0.16","text":""},{"location":"intro/releases/#python-extensions","title":"Python extensions","text":"<p>A new build mode is added to <code>codon</code> called <code>pyext</code> which compiles to Python extension modules, allowing Codon code to be imported and called directly from Python (similar to Cython). Please see the docs for more information and usage examples.</p>"},{"location":"intro/releases/#standard-library-updates_1","title":"Standard library updates","text":"<ul> <li> <p>Various additions to the standard library, such as <code>math.fsum()</code> and   the built-in <code>pow()</code>.</p> </li> <li> <p>Added <code>complex64</code>, which is a complex number with 32-bit float real and   imaginary components.</p> </li> <li> <p>Better <code>Int[N]</code> and <code>UInt[N]</code> support: can now convert ints wider than   64-bit to string; now supports more operators.</p> </li> </ul>"},{"location":"intro/releases/#more-python-specific-optimizations","title":"More Python-specific optimizations","text":"<p>New optimizations for specific patterns including <code>any()</code>/<code>all()</code> and multiple list concatenations. These patterns are now recognized and optimized in Codon's IR.</p>"},{"location":"intro/releases/#static-expressions","title":"Static expressions","text":"<p>Codon now supports more compile-time static functions, such as <code>staticenumerate</code>.</p>"},{"location":"intro/releases/#v015","title":"v0.15","text":""},{"location":"intro/releases/#union-types","title":"Union types","text":"<p>Codon adds support for union types (e.g., <code>Union[int, float]</code>):</p> <pre><code>def foo(cmd) -&gt; Union:\n    if cmd == 'int': return 1\n    else: return \"s\"\nfoo('int')        # type is Union[int,str]\n5 + foo('int')    # 6\n'a' + foo('str')  # as\n</code></pre>"},{"location":"intro/releases/#dynamic-inheritance","title":"Dynamic inheritance","text":"<p>Dynamic inheritance and polymorphism are now supported:</p> <pre><code>class A:\n    def __repr__(): return 'A'\nclass B(A):\n    def __repr__(): return 'B'\nl = [A(), B(), A()]  # type of l is List[A]\nprint(l)  # [A, B, A]\n</code></pre> <p>This feature is still a work in progress.</p>"},{"location":"intro/releases/#llvm-upgrade_1","title":"LLVM upgrade","text":"<p>Upgraded to LLVM 15 (from 12). Note that LLVM 15 now uses opaque pointers, e.g. <code>ptr</code> instead of <code>i8*</code> or <code>i64*</code>, which affects <code>@llvm</code> functions written in Codon as well as LLVM IR output of <code>codon build</code>.</p>"},{"location":"intro/releases/#standard-library","title":"Standard library","text":"<p><code>random</code> module now matches Python exactly for the same seed.</p>"},{"location":"intro/releases/#v014","title":"v0.14","text":""},{"location":"intro/releases/#gpu-support","title":"GPU support","text":"<p>GPU kernels can now be written and called in Codon. Existing loops can be parallelized on the GPU with the <code>@par(gpu=True)</code> annotation. Please see the docs for more information and examples.</p>"},{"location":"intro/releases/#semantics","title":"Semantics","text":"<p>Added <code>-numerics</code> flag, which specifies semantics of various numeric operations:</p> <ul> <li><code>-numerics=c</code> (default): C semantics; best performance</li> <li><code>-numerics=py</code>: Python semantics (checks for zero divisors   and raises <code>ZeroDivisionError</code>, and adds domain checks to <code>math</code>   functions); might slightly decrease performance.</li> </ul>"},{"location":"intro/releases/#types","title":"Types","text":"<p>Added <code>float32</code> type to represent 32-bit floats (equivalent to C's <code>float</code>). All <code>math</code> functions now have <code>float32</code> overloads.</p>"},{"location":"intro/releases/#parallelism","title":"Parallelism","text":"<p>Added <code>collapse</code> option to <code>@par</code>:</p> <pre><code>@par(collapse=2)  # parallelize entire iteration space of 2 loops\nfor i in range(N):\n    for j in range(N):\n        do_work(i, j)\n</code></pre>"},{"location":"intro/releases/#standard-library_1","title":"Standard library","text":"<p>Added <code>collections.defaultdict</code>.</p>"},{"location":"intro/releases/#python-interoperability","title":"Python interoperability","text":"<p>Various Python interoperability improvements: can now use <code>isinstance</code> on Python objects/types and can now catch Python exceptions by name.</p>"},{"location":"intro/releases/#v013","title":"v0.13","text":""},{"location":"intro/releases/#language","title":"Language","text":""},{"location":"intro/releases/#scoping","title":"$ Scoping","text":"<p>Scoping was changed to match Python scoping. For example:</p> <pre><code>if condition:\n    x = 42\n\nprint(x)\n</code></pre> <p>If condition is <code>False</code>, referencing <code>x</code> causes a <code>NameError</code> to be raised at runtime, much like what happens in Python. There is zero new performance overhead for code using the old scoping; code using the new scoping as above generates a flag to indicate whether the given variable has been assigned.</p> <p>Moreover, variables can now be assigned to different types:</p> <pre><code>x = 42\nprint(x)  # 42\nx = 'hello'\nprint(x)  # hello\n</code></pre> <p>The same applies in Jupyter or JIT environments.</p>"},{"location":"intro/releases/#static-methods","title":"$ Static methods","text":"<p>Added support for <code>@staticmethod</code> method decorator. Class variables are also supported:</p> <pre><code>class Cls:\n    a = 5  # or \"a: ClassVar[int] = 5\" (PEP 526)\n\n    @staticmethod\n    def method():\n        print('hello world')\n\nc = Cls()\nCls.a, Cls.method(), c.a, c.method()  # supported\n</code></pre>"},{"location":"intro/releases/#tuple-handling","title":"Tuple handling","text":"<p>Arbitrary classes can now be converted to tuples via the <code>tuple()</code> function.</p>"},{"location":"intro/releases/#void-type","title":"Void type","text":"<p>The <code>void</code> type has been completely removed in favor of the new and Pythonic <code>NoneType</code>, which compiles to an empty LLVM struct. This does not affect C interoperability as the empty struct type is replaced by <code>void</code> by LLVM.</p>"},{"location":"intro/releases/#standard-library_2","title":"Standard library","text":"<p>The <code>re</code> module is now fully supported, and uses Google's <code>re2</code> as a backend. Future versions of Codon will also include an additional regex optimization pass to compile constant (\"known at compile time\") regular expressions to native code.</p>"},{"location":"intro/releases/#c-variables","title":"C variables","text":"<p>Global variables with C linkage can now be imported via <code>from C import</code>:</p> <pre><code># assumes the C variable \"long foo\"\nfrom C import foo: int\nprint(foo)\n</code></pre>"},{"location":"intro/releases/#parallelism_1","title":"Parallelism","text":"<p>Numerous improvements to the OpenMP backend, including the addition of task-based reductions:</p> <pre><code>total = 0\n@par\nfor a in some_arbitrary_generator():\n    total += do_work(a)  # now converted to task reduction\n</code></pre>"},{"location":"intro/releases/#python-interoperability_1","title":"Python interoperability","text":"<p>Included revamped <code>codon</code> module for Python, with <code>@codon.jit</code> decorator for compiling Python code in existing codebases. Further improved and optimized the Python bridge. Please see the docs for more information.</p>"},{"location":"intro/releases/#codon-ir","title":"Codon IR","text":"<p>New capture analysis pass for Codon IR for improving tasks such as dead code elimination and side effect analysis. This allows Codon IR to deduce whether arbitrary, compilable Python expressions have side effects, capture variables, and more.</p>"},{"location":"intro/releases/#code-generation-and-optimizations","title":"Code generation and optimizations","text":"<p>A new dynamic allocation optimization pass is included, which 1) removes unused allocations (e.g. instantiating a class but never using it) and 2) demotes small heap allocations to stack (<code>alloca</code>) allocations when possible. The latter optimization can frequently remove any overhead associated with instantiating most classes.</p>"},{"location":"intro/releases/#command-line-tool","title":"Command-line tool","text":"<p>The <code>codon</code> binary can now compile to shared libraries using the <code>-lib</code> option to <code>codon build</code> (or it can be deduced from a <code>.so</code> or <code>.dylib</code> extension on the output file name).</p>"},{"location":"intro/releases/#errors","title":"Errors","text":"<p>Added support for multiple error reporting.</p>"},{"location":"intro/roadmap/","title":"Roadmap","text":""},{"location":"intro/roadmap/#summary","title":"Summary","text":"<p>Codon's goal is to be as close to CPython as possible while still being fully statically compilable. While Codon already supports much of Python, there is still much to be done to fully realize its potential. Here is a high-level roadmap of the things we want to add, implement or explore.</p>"},{"location":"intro/roadmap/#core-features","title":"Core features","text":"<ul> <li>Type system improvements:</li> <li>First-class types and compile-time metaclasses</li> <li>Full class member deduction</li> <li>Implicit union types to support mixed-type collections</li> <li> <p>Variadic type arguments (e.g. <code>Foo[Bar, ...]</code>)</p> </li> <li> <p>Parallelism</p> </li> <li><code>async</code>/<code>await</code> support</li> <li><code>multiprocessing</code> support</li> <li>Automatic locking in parallel code (e.g. if mutating a     data structure shared between threads)</li> <li> <p>Race detection</p> </li> <li> <p>Compatibility with Python 3.10+:</p> </li> <li>Argument separators (<code>/</code> and <code>*</code>)</li> <li>Constructor object matching in the <code>match</code> statement</li> <li> <p>Support accessing various object properties (<code>__dict__</code>, <code>__slots__</code>     etc.) as much as possible in a static context</p> </li> <li> <p>Optional automatic switching between Codon and CPython (i.e.   compile only compatible functions and leave the rest to Python)</p> </li> <li> <p>Better error messages</p> </li> <li>Warning support</li> <li>Explain performance considerations</li> <li> <p>Explain that a CPython feature is not supported</p> </li> <li> <p>Modules and incremental compilation</p> </li> <li>Cache compilation modules</li> <li> <p>Fast generics compilation in debug mode for quick turnarounds</p> </li> <li> <p>Memory management</p> </li> <li>Auto-tune GC</li> <li> <p>Optional alternative memory management modes like reference     counting</p> </li> <li> <p>GPU support</p> </li> <li>Target Apple, AMD and Intel GPUs</li> <li> <p>GPU-specific compiler optimizations (e.g. for using various     Python constructs on the GPU)</p> </li> <li> <p>Interoperability with other languages</p> </li> <li>Direct C++ interoperability via Clang</li> <li>R interoperability</li> </ul>"},{"location":"intro/roadmap/#libraries","title":"Libraries","text":"<p>Currently, missing Python functionality can be easily accessed via a <code>from python import foo</code> statement, which is sufficient in most cases as many libraries are just thin wrappers around a C library and/or not performance-sensitive.</p> <p>However, in the near future, we would like to support the following modules natively:</p> <ul> <li>Python's standard library</li> <li>Complete builtins support</li> <li>1-to-1 compatibility with existing Python functions and modules</li> <li>File modules: <code>os</code>, <code>sys</code>, <code>struct</code>, <code>pathlib</code> and so on</li> <li> <p>Pretty much everything else on an as-needed basis</p> </li> <li> <p>Native NumPy, Pandas, etc.: Having Codon-native versions of the most   popular 3rd-party libraries would allow them to work with Codon's   other features like multithreading and GPU. We're currently prioritizing   NumPy and Pandas but aim to later target other popular libraries as well.</p> </li> <li> <p>As of Codon 0.18, NumPy is natively supported!</p> </li> <li> <p>Unicode support</p> </li> <li> <p>Python's testing infrastructure</p> </li> </ul>"},{"location":"intro/roadmap/#infrastructure-tools","title":"Infrastructure &amp; Tools","text":"<ul> <li> <p>Windows support</p> </li> <li> <p>A sane package manager similar to Rust's   Cargo</p> </li> <li> <p>Auto-detection of installed Python libraries</p> </li> <li> <p>Improved <code>codon.jit</code> library support</p> </li> <li>Better error messages</li> <li> <p>Better installation flow</p> </li> <li> <p>Fully static binary support like Go</p> </li> <li>Remove <code>libcodonrt</code> (runtime library) dependency if needed</li> <li> <p>Remove <code>libcpp</code> dependency</p> </li> <li> <p>Improved Jupyter support</p> </li> <li>Auto-completion and code inspection</li> <li> <p>Jupyter magic command support</p> </li> <li> <p>Plugins for Visual Studio Code, Vim, Emacs and so on</p> </li> </ul>"},{"location":"intro/roadmap/#documentation","title":"Documentation","text":"<ul> <li>Fully document major differences with CPython</li> <li>Document Codon IR API, with guides and tutorials</li> <li>Document all supported modules</li> </ul>"},{"location":"intro/roadmap/#nice-to-have","title":"Nice to have","text":"<ul> <li>Implement Codon in Codon</li> </ul>"},{"location":"language/basics/","title":"Basics","text":""},{"location":"language/basics/#summary","title":"Summary","text":"<p>If you know Python, you already know 99% of Codon. This section covers the Codon language as well as some of the key differences and additional features on top of Python.</p>"},{"location":"language/basics/#printing","title":"Printing","text":"<pre><code>print('hello world')\n\nfrom sys import stderr\nprint('hello world', end='', file=stderr)\n</code></pre>"},{"location":"language/basics/#comments","title":"Comments","text":"<pre><code># Codon comments start with \"# 'and go until the end of the line\n\n\"\"\"\nMulti-line comments are\npossible like this.\n\"\"\"\n</code></pre>"},{"location":"language/basics/#literals","title":"Literals","text":"<pre><code># Booleans\nTrue   # type: bool\nFalse\n\n# Numbers\na = 1             # type: int; a signed 64-bit integer\nb = 1.12          # type: float; a 64-bit float (just like \"double\" in C)\nc = 5u            # unsigned int; an unsigned 64-bit int\nd = Int[8](12)    # 8-bit signed integer; you can go all the way to Int[2048]\ne = UInt[8](200)  # 8-bit unsigned integer\nf = byte(3)       # Codon's byte is equivalent to C's char; equivalent to Int[8]\n\nh = 0x12AF   # hexadecimal integers are also welcome\ng = 3.11e+9  # scientific notation is also supported\ng = .223     # and this is also float\ng = .11E-1   # and this as well\n\n# Strings\ns = 'hello! \"^_^\" '              # type: str\nt = \"hello there! \\t \\\\ '^_^' \"  # \\t is a tab character; \\\\ stands for \\\nraw = r\"hello\\n\"                 # raw strings do not escape slashes; this would print \"hello\\n\"\nfstr = f\"a is {a + 1}\"           # an f-string; prints \"a is 2\"\nfstr = f\"hi! {a+1=}\"             # an f-string; prints \"hi! a+1=2\"\nt = \"\"\"\nhello!\nmultiline string\n\"\"\"\n\n# The following escape sequences are supported:\n#   \\\\, \\', \\\", \\a, \\b, \\f, \\n, \\r, \\t, \\v,\n#   \\xHHH (HHH is hex code), \\OOO (OOO is octal code)\n</code></pre>"},{"location":"language/basics/#assignments-and-operators","title":"Assignments and operators","text":"<pre><code>a = 1 + 2              # this is 3\na = (1).__add__(2)     # you can use a function call instead of an operator; this is also 3\na = int.__add__(1, 2)  # this is equivalent to the previous line\nb = 5 / 2.0            # this is 2.5\nc = 5 // 2             # this is 2; // is an integer division\na *= 2                 # a is now 6\n</code></pre> <p>Here is the list of binary operators and each one's associated magic method:</p> Operator Magic method Description <code>+</code> <code>__add__</code> addition <code>-</code> <code>__sub__</code> subtraction <code>*</code> <code>__mul__</code> multiplication <code>/</code> <code>__truediv__</code> float (true) division <code>//</code> <code>__floordiv__</code> integer (floor) division <code>**</code> <code>__pow__</code> exponentiation <code>%</code> <code>__mod__</code> modulo <code>@</code> <code>__matmul__</code> matrix multiplication <code>&amp;</code> <code>__and__</code> bitwise and <code>|</code> <code>__or__</code> bitwise or <code>^</code> <code>__xor__</code> bitwise xor <code>&lt;&lt;</code> <code>__lshift__</code> left bit shift <code>&gt;&gt;</code> <code>__rshift__</code> right bit shift <code>&lt;</code> <code>__lt__</code> less than <code>&lt;=</code> <code>__le__</code> less than or equal to <code>&gt;</code> <code>__gt__</code> greater than <code>&gt;=</code> <code>__ge__</code> greater than or equal to <code>==</code> <code>__eq__</code> equal to <code>!=</code> <code>__ne__</code> not equal to <code>in</code> <code>__contains__</code> belongs to <code>and</code> none boolean and (short-circuits) <code>or</code> none boolean or (short-circuits) <p>Codon also has the following unary operators:</p> Operator Magic method Description <code>~</code> <code>__invert__</code> bitwise not <code>+</code> <code>__pos__</code> unary positive <code>-</code> <code>__neg__</code> unary negation <code>not</code> none boolean negation"},{"location":"language/basics/#control-flow","title":"Control flow","text":""},{"location":"language/basics/#conditionals","title":"Conditionals","text":"<p>Codon supports the standard Python conditional syntax:</p> <pre><code>if a or b or some_cond():\n    print(1)\nelif whatever() or 1 &lt; a &lt;= b &lt; c &lt; 4:  # chained comparisons are supported\n    print('meh...')\nelse:\n    print('lo and behold!')\n\na = b if sth() else c  # ternary conditional operator\n</code></pre> <p>Codon extends the Python conditional syntax with a <code>match</code> statement, which is inspired by Rust's:</p> <pre><code>match a + some_heavy_expr():  # assuming that the type of this expression is int\n    case 1:         # is it 1?\n        print('hi')\n    case 2 ... 10:  # is it 2, 3, 4, 5, 6, 7, 8, 9 or 10?\n        print('wow!')\n    case _:         # \"default\" case\n        print('meh...')\n\nmatch bool_expr():  # now it's a bool expression\n    case True:\n        print('yay')\n    case False:\n        print('nay')\n\nmatch str_expr():  # now it's a str expression\n    case 'abc': print(\"it's ABC time!\")\n    case 'def' | 'ghi':  # you can chain multiple rules with the \"|\" operator\n        print(\"it's not ABC time!\")\n    case s if len(s) &gt; 10: print(\"so looong!\")  # conditional match expression\n    case _: assert False\n\nmatch some_tuple:  # assuming type of some_tuple is Tuple[int, int]\n    case (1, 2): ...\n    case (a, _) if a == 42:  # you can do away with useless terms with an underscore\n        print('hitchhiker!')\n    case (a, 50 ... 100) | (10 ... 20, b):  # you can nest match expressions\n        print('complex!')\n\nmatch list_foo():\n    case []:                   # [] matches an empty list\n        print('A')\n    case [1, 2, 3]:            # make sure that list_foo() returns List[int] though!\n        print('B')\n    case [1, 2, ..., 5]:       # matches any list that starts with 1 and 2 and ends with 5\n        print('C')\n    case [..., 6] | [6, ...]:  # matches a list that starts or ends with 6\n        print('D')\n    case [..., w] if w &lt; 0:    # matches a list that ends with a negative integer\n        print('E')\n    case [...]:                # any other list\n        print('F')\n</code></pre> <p>You can mix, match and chain match rules as long as the match type matches the expression type.</p>"},{"location":"language/basics/#loops","title":"Loops","text":"<p>Standard fare:</p> <pre><code>a = 10\nwhile a &gt; 0:  # prints even numbers from 9 to 1\n    a -= 1\n    if a % 2 == 1:\n        continue\n    print(a)\n\nfor i in range(10):  # prints numbers from 0 to 7, inclusive\n    print(i)\n    if i &gt; 6:\n        break\n</code></pre> <p><code>for</code> construct can iterate over any generator, which means any object that implements the <code>__iter__</code> magic method. In practice, generators, lists, sets, dictionaries, homogenous tuples, ranges, and many more types implement this method. If you need to implement one yourself, just keep in mind that <code>__iter__</code> is a generator and not a function.</p>"},{"location":"language/basics/#imports","title":"Imports","text":"<p>You can import functions and classes from another Codon module by doing:</p> <pre><code># Create foo.codon with a bunch of useful methods\nimport foo\n\nfoo.useful1()\np = foo.FooType()\n\n# Create bar.codon with a bunch of useful methods\nfrom bar import x, y\nx(y)\n\nfrom bar import z as bar_z\nbar_z()\n</code></pre> <p><code>import foo</code> looks for <code>foo.codon</code> or <code>foo/__init__.codon</code> in the current directory.</p>"},{"location":"language/basics/#exceptions","title":"Exceptions","text":"<p>Again, if you know how to do this in Python, you know how to do it in Codon:</p> <pre><code>def throwable():\n     raise ValueError(\"doom and gloom\")\n\ntry:\n    throwable()\nexcept ValueError as e:\n    print(\"we caught the exception\")\nexcept:\n    print(\"ouch, we're in deep trouble\")\nfinally:\n    print(\"whatever, it's done\")\n</code></pre> <p>\u26a0\ufe0f Warning: Right now, Codon cannot catch multiple exceptions in one statement. Thus <code>catch (Exc1, Exc2, Exc3) as var</code> will not compile, since the type of <code>var</code> needs to be known ahead of time.</p> <p>If you have an object that implements <code>__enter__</code> and <code>__exit__</code> methods to manage its lifetime (say, a <code>File</code>), you can use a <code>with</code> statement to make your life easier:</p> <pre><code>with open('foo.txt') as f, open('foo_copy.txt', 'w') as fo:\n    for l in f:\n        fo.write(l)\n</code></pre>"},{"location":"language/classes/","title":"Classes","text":""},{"location":"language/classes/#summary","title":"Summary","text":"<p>Codon supports classes just like Python. However, you must declare class members and their types in the preamble of each class (like you would do with Python's dataclasses):</p> <pre><code>class Foo:\n    x: int\n    y: int\n\n    def __init__(self, x: int, y: int):  # constructor\n        self.x, self.y = x, y\n\n    def method(self):\n        print(self.x, self.y)\n\nf = Foo(1, 2)\nf.method()  # prints \"1 2\"\n</code></pre> <p>Unlike Python, Codon supports method overloading:</p> <pre><code>class Foo:\n    x: int\n    y: int\n\n    def __init__(self):                    # constructor\n        self.x, self.y = 0, 0\n\n    def __init__(self, x: int, y: int):    # another constructor\n        self.x, self.y = x, y\n\n    def __init__(self, x: int, y: float):  # yet another constructor\n        self.x, self.y = x, int(y)\n\n    def method(self: Foo):\n        print(self.x, self.y)\n\nFoo().method()          # prints \"0 0\"\nFoo(1, 2).method()      # prints \"1 2\"\nFoo(1, 2.3).method()    # prints \"1 2\"\nFoo(1.1, 2.3).method()  # error: there is no Foo.__init__(float, float)\n</code></pre> <p>Classes can also be generic:</p> <pre><code>class Container[T]:\n    elements: List[T]\n\n    def __init__(self, elements: List[T]):\n        self.elements = elements\n</code></pre> <p>Classes create objects that are passed by reference:</p> <pre><code>class Point:\n    x: int\n    y: int\n\np = Point(1, 2)\nq = p  # this is a reference!\np.x = 2\nprint((p.x, p.y), (q.x, q.y))  # (2, 2), (2, 2)\n</code></pre> <p>If you need to copy an object's contents, implement the <code>__copy__</code> magic method and use <code>q = copy(p)</code> instead.</p> <p>Classes can inherit from other classes:</p> <pre><code>class NamedPoint(Point):\n    name: str\n\n    def __init__(self, x: int, y: int, name: str):\n        super().__init__(x, y)\n        self.name = name\n</code></pre> <p>\u26a0\ufe0f Warning: Currently, inheritance in Codon is still under active development. Treat it as a beta feature.</p>"},{"location":"language/classes/#named-tuples","title":"Named tuples","text":"<p>Codon also supports pass-by-value types via the <code>@tuple</code> annotation, which are effectively named tuples (equivalent to Python's <code>collections.namedtuple</code>):</p> <pre><code>@tuple\nclass Point:\n    x: int\n    y: int\n\np = Point(1, 2)\nq = p  # this is a copy!\nprint((p.x, p.y), (q.x, q.y))  # (1, 2), (1, 2)\n</code></pre> <p>However, named tuples are immutable. The following code will not compile:</p> <pre><code>p = Point(1, 2)\np.x = 2  # error: immutable type\n</code></pre> <p>You can also add methods to named tuples:</p> <pre><code>@tuple\nclass Point:\n    x: int\n    y: int\n\n    def __new__():          # named tuples are constructed via __new__, not __init__\n        return Point(0, 1)\n\n    def some_method(self):\n        return self.x + self.y\n\np = Point()             # p is (0, 1)\nprint(p.some_method())  # 1\n</code></pre>"},{"location":"language/classes/#type-extensions","title":"Type extensions","text":"<p>Suppose you have a class that lacks a method or an operator that might be really useful. Codon provides an <code>@extend</code> annotation that allows programmers to add and modify methods of various types at compile time, including built-in types like <code>int</code> or <code>str</code>. This actually allows much of the functionality of built-in types to be implemented in Codon as type extensions in the standard library.</p> <pre><code>class Foo:\n    ...\n\nf = Foo(...)\n\n# We need foo.cool() but it does not exist... not a problem for Codon\n@extend\nclass Foo:\n    def cool(self: Foo):\n        ...\n\nf.cool()  # works!\n\n# Let's add support for adding integers and strings:\n@extend\nclass int:\n    def __add__(self: int, other: str):\n        return self + int(other)\n\nprint(5 + '4')  # 9\n</code></pre> <p>Note that all type extensions are performed strictly at compile time and incur no runtime overhead.</p> <p>\u26a0\ufe0f Warning: Type extensions in Codon are also a beta feature.</p>"},{"location":"language/classes/#magic-methods","title":"Magic methods","text":"<p>Here is a list of useful magic methods that you might want to add and overload:</p> Magic method Description <code>__copy__</code> copy-constructor for <code>copy</code> method <code>__len__</code> for <code>len</code> method <code>__bool__</code> for <code>bool</code> method and condition checking <code>__getitem__</code> overload <code>obj[key]</code> <code>__setitem__</code> overload <code>obj[key] = value</code> <code>__delitem__</code> overload <code>del obj[key]</code> <code>__iter__</code> support iterating over the object <code>__repr__</code> support printing and <code>str</code> conversion"},{"location":"language/collections/","title":"Collections","text":""},{"location":"language/collections/#summary","title":"Summary","text":"<p>Collections are largely the same as in Python:</p> <pre><code>l = [1, 2, 3]                         # type: List[int]; a list of integers\ns = {1.1, 3.3, 2.2, 3.3}              # type: Set[float]; a set of floats\nd = {1: 'hi', 2: 'ola', 3: 'zdravo'}  # type: Dict[int, str]; a dictionary of int to str\n\nln = []                               # an empty list whose type is inferred based on usage\nln = List[int]()                      # an empty list with explicit element type\ndn = {}                               # an empty dict whose type is inferred based on usage\ndn = Dict[int, float]()               # an empty dictionary with explicit element types\nsn = set()                            # an empty set whose type is inferred based on usage\nsn = Set[str]()                       # an empty set with explicit element type\n</code></pre> <p>Lists also take an optional <code>capacity</code> constructor argument, which can be useful when creating large lists:</p> <pre><code>squares = list(capacity=1_000_000)  # list with room for 1M elements\n\n# Fill the list\nfor i in range(1_000_000):\n    squares.append(i ** 2)\n</code></pre> <p>\u2139\ufe0f Info: Dictionaries and sets are unordered and are based on klib.</p>"},{"location":"language/collections/#comprehensions","title":"Comprehensions","text":"<p>Comprehensions are a nifty, Pythonic way to create collections, and are fully supported by Codon:</p> <pre><code>l = [i for i in range(5)]                                  # type: List[int]; l is [0, 1, 2, 3, 4]\nl = [i for i in range(15) if i % 2 == 1 if i &gt; 10]         # type: List[int]; l is [11, 13]\nl = [i * j for i in range(5) for j in range(5) if i == j]  # l is [0, 1, 4, 9, 16]\n\ns = {abs(i - j) for i in range(5) for j in range(5)}  # s is {0, 1, 2, 3, 4}\nd = {i: f'item {i+1}' for i in range(3)}              # d is {0: \"item 1\", 1: \"item 2\", 2: \"item 3\"}\n</code></pre> <p>You can also use generators to create collections:</p> <pre><code>g = (i for i in range(10))\nprint(list(g))  # prints list of integers from 0 to 9, inclusive\n</code></pre>"},{"location":"language/collections/#tuples","title":"Tuples","text":"<pre><code>t = (1, 2.3, 'hi')  # type: Tuple[int, float, str]\nt[1]                # type: float\nu = (1, )           # type: Tuple[int]\n</code></pre> <p>As all types must be known at compile time, tuple indexing works only if a tuple is homogenous (all types are the same) or if the value of the index is known at compile time.</p> <p>You can, however, iterate over heterogenous tuples in Codon. This is achieved behind the scenes by unrolling the loop to accommodate the different types.</p> <pre><code>t = (1, 2.3, 'hi')\nt[1]  # works because 1 is a constant int\n\nx = int(argv[1])\nt[x]  # compile error: x is not known at compile time\n\n# This is a homogenous tuple (all member types are the same)\nu = (1, 2, 3)  # type: Tuple[int, int, int]\nu[x]           # works because tuple members share the same type regardless of x\nfor i in u:    # works\n    print(i)\n\n# Also works\nv = (42, 'x', 3.14)\nfor i in v:\n    print(i)\n</code></pre> <p>\u26a0\ufe0f Warning: Just like in Python, tuples are immutable, so <code>a = (1, 2); a[1] = 1</code> will not compile.</p> <p>Codon supports most of Python's tuple unpacking syntax:</p> <pre><code>x, y = 1, 2                # x is 1, y is 2\n(x, (y, z)) = 1, (2, 3)    # x is 1, y is 2, z is 3\n[x, (y, z)] = (1, [2, 3])  # x is 1, y is 2, z is 3\n\nl = range(1, 8)    # l is [1, 2, 3, 4, 5, 6, 7]\na, b, *mid, c = l  # a is 1, b is 2, mid is [3, 4, 5, 6], c is 7\na, *end = l        # a is 1, end is [2, 3, 4, 5, 6, 7]\n*beg, c = l        # c is 7, beg is [1, 2, 3, 4, 5, 6]\n(*x, ) = range(3)  # x is [0, 1, 2]\n*x = range(3)      # error: this does not work\n\n*sth, a, b = (1, 2, 3, 4)      # sth is (1, 2), a is 3, b is 4\n*sth, a, b = (1.1, 2, 3.3, 4)  # error: this only works on homogenous tuples for now\n\n(x, y), *pff, z = [1, 2], 'this'\nprint(x, y, pff, z)               # x is 1, y is 2, pff is an empty tuple --- () ---, and z is \"this\"\n\ns, *q = 'XYZ'  # works on strings as well; s is \"X\" and q is \"YZ\"\n</code></pre>"},{"location":"language/collections/#strong-typing","title":"Strong typing","text":"<p>Because Codon is strongly typed, these won't compile:</p> <pre><code>l = [1, 's']   # is it a List[int] or List[str]? you cannot mix-and-match types\nd = {1: 'hi'}\nd[2] = 3       # d is a Dict[int, str]; the assigned value must be a str\n\nt = (1, 2.2)  # Tuple[int, float]\nlt = list(t)  # compile error: t is not homogenous\n\nlp = [1, 2.1, 3, 5]  # compile error: Codon will not automatically cast a float to an int\n</code></pre> <p>This will work, though:</p> <pre><code>u = (1, 2, 3)\nlu = list(u)  # works: u is homogenous\n</code></pre>"},{"location":"language/extra/","title":"Other types and features","text":""},{"location":"language/extra/#summary","title":"Summary","text":"<p>Codon supports a number of additional types that are not present in plain Python.</p>"},{"location":"language/extra/#arbitrary-width-integers","title":"Arbitrary-width integers","text":"<p>Codon's <code>int</code> type is a 64-bit signed integer. However, Codon supports arbitrary-width signed and unsigned integers:</p> <pre><code>a = Int[16](42)    # signed 16-bit integer 42\nb = UInt[128](99)  # unsigned 128-bit integer 99\n</code></pre> <p>The Codon standard library provides shorthands for the common variants:</p> <ul> <li><code>i8</code>/<code>u8</code>: signed/unsigned 8-bit integer</li> <li><code>i16</code>/<code>u16</code>: signed/unsigned 16-bit integer</li> <li><code>i32</code>/<code>u32</code>: signed/unsigned 32-bit integer</li> <li><code>i64</code>/<code>u64</code>: signed/unsigned 64-bit integer</li> </ul>"},{"location":"language/extra/#32-bit-float","title":"32-bit float","text":"<p>Codon's <code>float</code> type is a 64-bit floating point value. Codon also supports <code>float32</code> (or <code>f32</code> as a shorthand), representing a 32-bit floating point value (like C's <code>float</code>).</p>"},{"location":"language/extra/#pointers","title":"Pointers","text":"<p>Codon has a <code>Ptr[T]</code> type that represents a pointer to an object of type <code>T</code>. Pointers can be useful when interfacing with C. The <code>__ptr__</code> keyword can also be used to obtain a pointer to a variable:</p> <pre><code>p = Ptr[int](100)  # allocate a buffer of 100 ints\np = Ptr[int]()     # null pointer\n\nx = 42\np = __ptr__(x)     # pointer to x, like \"&amp;x\" in C\n\nfrom C import foo(Ptr[int])\nfoo(p)             # pass pointer to C function\n</code></pre> <p>The <code>cobj</code> alias corresponds to <code>void*</code> in C and represents a generic C or C++ object.</p> <p>\u26a0\ufe0f Warning: Using pointers directly circumvents any runtime checks, so dereferencing a null pointer, for example, will cause a segmentation fault just like in C.</p>"},{"location":"language/extra/#static-arrays","title":"Static arrays","text":"<p>The <code>__array__</code> keyword can be used to allocate static arrays on the stack:</p> <pre><code>def foo(n):\n    arr = __array__[int](5)  # similar to \"long arr[5]\" in C\n    arr[0] = 11\n    arr[1] = arr[0] + 1\n    ...\n</code></pre>"},{"location":"language/ffi/","title":"Foreign function interface","text":""},{"location":"language/ffi/#summary","title":"Summary","text":"<p>Codon can seamlessly call functions from C and Python:</p> <pre><code>from C import pow(float, float) -&gt; float\npow(2.0, 2.0)  # 4.0\n\n# Import and rename function\n# cobj is a C pointer (void*, char*, etc.)\n# None can be used to represent C's void\nfrom C import puts(cobj) -&gt; None as print_line\nprint_line(\"hello\".c_str())  # prints \"hello\"; c_str() converts Codon str to C string\n</code></pre> <p><code>from C import</code> only works if the symbol is available to the program. If you are running your programs via <code>codon</code>, you can link dynamic libraries with <code>-l</code>: <code>codon run -l /path/to/library.so ...</code>.</p> <p>You can also load shared libraries with <code>dlopen</code>:</p> <pre><code>LIBRARY = \"somelib.so\"\nfrom C import LIBRARY.mymethod(int, float) -&gt; cobj\nfrom C import LIBRARY.myothermethod(int, float) -&gt; cobj as my2\nfoo = mymethod(1, 2.2)\nfoo2 = my2(4, 3.2)\n</code></pre> <p>\u26a0\ufe0f Warning: When importing C functions, you must explicitly specify argument and return types.</p> <p>How about Python? If you have set the <code>CODON_PYTHON</code> environment variable to point to the Python library, you can do:</p> <pre><code>from python import mymodule.myfunction(str) -&gt; int as foo\nprint(foo(\"bar\"))\n</code></pre> <p>You might want to execute more complex Python code within Codon. To that end, you can use Codon's <code>@python</code> annotation:</p> <pre><code>@python\ndef scipy_eigenvalues(i: List[List[float]]) -&gt; List[float]:\n    # Code within this block is executed by the Python interpreter,\n    # so it must be valid Python code.\n    import scipy.linalg\n    import numpy as np\n    data = np.array(i)\n    eigenvalues, _ = scipy.linalg.eig(data)\n    return list(eigenvalues)\nprint(scipy_eigenvalues([[1.0, 2.0], [3.0, 4.0]]))  # [-0.372281, 5.37228]\n</code></pre> <p>Codon will automatically bridge any object that implements the <code>__to_py__</code> and <code>__from_py__</code> magic methods. All standard Codon types already implement these methods.</p>"},{"location":"language/functions/","title":"Functions","text":""},{"location":"language/functions/#summary","title":"Summary","text":"<p>Functions are defined as follows:</p> <pre><code>def foo(a, b, c):\n    return a + b + c\n\nprint(foo(1, 2, 3))  # prints 6\n</code></pre> <p>Functions don't have to return a value:</p> <pre><code>def proc(a, b):\n    print(a, 'followed by', b)\n\nproc(1, 's')\n\n\ndef proc2(a, b):\n    if a == 5:\n        return\n    print(a, 'followed by', b)\n\nproc2(1, 's')\nproc2(5, 's')  # this prints nothing\n</code></pre> <p>Codon is a strongly-typed language, so you can restrict argument and return types:</p> <pre><code>def fn(a: int, b: float):\n    return a + b  # this works because int implements __add__(float)\n\nfn(1, 2.2)  # 3.2\nfn(1.1, 2)  # error: 1.1. is not an int\n\n\ndef fn2(a: int, b):\n    return a - b\n\nfn2(1, 2)    # -1\nfn2(1, 1.1)  # -0.1; works because int implements __sub__(float)\nfn2(1, 's')  # error: there is no int.__sub__(str)!\n\n\ndef fn3(a, b) -&gt; int:\n    return a + b\n\nfn3(1, 2)      # works, since 1 + 2 is an int\nfn3('s', 'u')  # error: 's'+'u' returns 'su' which is str\n               # but the signature indicates that it must return int\n</code></pre> <p>Default and named arguments are also supported:</p> <pre><code>def foo(a, b: int, c: float = 1.0, d: str = 'hi'):\n    print(a, b, c, d)\n\nfoo(1, 2)             # prints \"1 2 1 hi\"\nfoo(1, d='foo', b=1)  # prints \"1 1 1 foo\"\n</code></pre> <p>As are optional arguments:</p> <pre><code># type of b promoted to Optional[int]\ndef foo(a, b: int = None):\n    print(a, b + 1)\n\nfoo(1, 2)  # prints \"1 3\"\nfoo(1)     # raises ValueError, since b is None\n</code></pre>"},{"location":"language/functions/#generics","title":"Generics","text":"<p>Codon emulates Python's lax runtime type checking using a technique known as monomorphization. If a function has an argument without a type definition, Codon will treat it as a generic function, and will generate different instantiations for each different invocation:</p> <pre><code>def foo(x):\n    print(x)  # print relies on typeof(x).__repr__(x) method to print the representation of x\n\nfoo(1)        # Codon automatically generates foo(x: int) and calls int.__repr__ when needed\nfoo('s')      # Codon automatically generates foo(x: str) and calls str.__repr__ when needed\nfoo([1, 2])   # Codon automatically generates foo(x: List[int]) and calls List[int].__repr__ when needed\n</code></pre> <p>But what if you need to mix type definitions and generic types? Say, your function can take a list of anything? You can use generic type parameters:</p> <pre><code>def foo(x: List[T], T: type):\n    print(x)\n\nfoo([1, 2])           # prints [1, 2]\nfoo(['s', 'u'])       # prints [s, u]\nfoo(5)                # error: 5 is not a list!\nfoo(['s', 'u'], int)  # fails: T is int, so foo expects List[int] but it got List[str]\n\n\ndef foo(x, R: type) -&gt; R:\n    print(x)\n    return 1\n\nfoo(4, int)  # prints 4, returns 1\nfoo(4, str)  # error: return type is str, but foo returns int!\n</code></pre> <p>\u2139\ufe0f Info: Coming from C++? <code>foo(x: List[T], T: type): ...</code> is roughly the same as <code>template&lt;typename T, typename U&gt; U foo(T x) { ... }</code>.</p> <p>Generic type parameters are an optional way to enforce various typing constraints.</p>"},{"location":"language/generators/","title":"Generators","text":""},{"location":"language/generators/#summary","title":"Summary","text":"<p>Codon supports generators, and in fact they are heavily optimized in the compiler so as to typically eliminate any overhead:</p> <pre><code>def gen(n):\n    i = 0\n    while i &lt; n:\n        yield i ** 2\n        i += 1\n\nprint(list(gen(10)))  # prints [0, 1, 4, ..., 81]\nprint(list(gen(0)))   # prints []\n</code></pre> <p>You can also use <code>yield</code> to implement coroutines: <code>yield</code> suspends the function, while <code>(yield)</code> (i.e. with parenthesis) receives a value, as in Python.</p> <pre><code>def mysum(start):\n    m = start\n    while True:\n        a = (yield)     # receives the input of coroutine.send() call\n        if a == -1:\n            break       # exits the coroutine\n        m += a\n    yield m\n\niadder = mysum(0)       # assign a coroutine\nnext(iadder)            # activate it\nfor i in range(10):\n    iadder.send(i)      # send a value to coroutine\nprint(iadder.send(-1))  # prints 45\n</code></pre> <p>Generator expressions are also supported:</p> <pre><code>squares = (i ** 2 for i in range(10))\nfor i,s in enumerate(squares):\n    print(i, 'x', i, '=', s)\n</code></pre>"},{"location":"language/llvm/","title":"Inline LLVM IR","text":""},{"location":"language/llvm/#summary","title":"Summary","text":"<p>Codon allows inline LLVM IR via the <code>@llvm</code> annotation:</p> <pre><code>@llvm\ndef llvm_add(a: int, b: int) -&gt; int:\n    %res = add i64 %a, %b\n    ret i64 %res\n\nprint(llvm_add(3, 4))  # 7\n</code></pre> <p>Note that LLVM functions must explicitly specify argument and return types.</p> <p>LLVM functions can also be generic, and a format specifier in the body will be replaced by the appropriate LLVM type:</p> <pre><code>@llvm\ndef llvm_add[T](a: T, b: T) -&gt; T:\n    %res = add {=T} %a, %b\n    ret {=T} %res\n\nprint(llvm_add(3, 4))          # 7\nprint(llvm_add(i8(5), i8(6)))  # 11\n</code></pre> <p>You can also access LLVM intrinsics with <code>declare</code>:</p> <pre><code>@llvm\ndef popcnt(n: int) -&gt; int:\n    declare i64 @llvm.ctpop.i64(i64)\n    %0 = call i64 @llvm.ctpop.i64(i64 %n)\n    ret i64 %0\n\nprint(popcnt(42))  # 3\n</code></pre>"},{"location":"language/llvm/#annotations","title":"Annotations","text":"<p>Sometimes it can be helpful to annotate <code>@llvm</code> functions to give the compiler more information as to how they behave. Codon has a number of default annotations for LLVM functions (all of which also apply to external/C functions):</p> <ul> <li> <p><code>@pure</code>: Function does not capture arguments (aside from   return value capturing as in <code>def foo(x): return x</code>), does not   modify arguments, and has no side effects. This is a   mathematically \"pure\" function.</p> </li> <li> <p><code>@no_side_effect</code>: Very similar to <code>@pure</code> but function may   return different results on different calls, such as the C   function <code>time()</code>.</p> </li> <li> <p><code>@nocapture</code>: Function does not capture any of its arguments   (again excluding return value capturing).</p> </li> <li> <p><code>@self_captures</code>: Function's first (<code>self</code>) argument captures   the other arguments, an example being <code>List.__setitem__()</code>.</p> </li> </ul> <p>These are mutually-exclusive annotations. Another complementary annotation <code>@derives</code> can be used to indicate that the return value of the function captures its arguments.</p> <p>These annotations are completely optional and do not affect program semantics.</p>"},{"location":"language/statics/","title":"Statics","text":""},{"location":"language/statics/#summary","title":"Summary","text":"<p>Sometimes, certain values or conditions need to be known at compile time. For example, the bit width <code>N</code> of an integer type <code>Int[N]</code>, or the size <code>M</code> of a static array <code>__array__[int](M)</code> need to be compile time constants.</p> <p>To accomodate this, Codon uses static values, i.e. values that are known and can be operated on at compile time. <code>Static[T]</code> represents a static value of type <code>T</code>. Currently, <code>T</code> can only be <code>int</code> or <code>str</code>.</p> <p>For example, we can parameterize the bit width of an integer type as follows:</p> <pre><code>N: Static[int] = 32\n\na = Int[N](10)      # 32-bit integer 10\nb = Int[2 * N](20)  # 64-bit integer 20\n</code></pre> <p>All of the standard arithmetic operations can be applied to static integers to produce new static integers.</p> <p>Statics can also be passed to the <code>codon</code> compiler via the <code>-D</code> flag, as in <code>-DN=32</code>.</p> <p>Classes can also be parameterized by statics:</p> <pre><code>class MyInt[N: Static[int]]:\n    n: Int[N]\n\nx = MyInt[16](i16(42))\n</code></pre>"},{"location":"language/statics/#static-evaluation","title":"Static evaluation","text":"<p>In certain cases a program might need to check a particular type and perform different actions based on it. For example:</p> <pre><code>def flatten(x):\n    if isinstance(x, list):\n        for a in x:\n            flatten(a)\n    else:\n        print(x)\n\nflatten([[1,2,3], [], [4, 5], [6]])\n</code></pre> <p>Standard static typing on this program would be problematic since, if <code>x</code> is an <code>int</code>, it would not be iterable and hence would produce an error on <code>for a in x</code>. Codon solves this problem by evaluating certain conditions at compile time, such as <code>isinstance(x, list)</code>, and avoiding type checking blocks that it knows will never be reached. In fact, this program works and flattens the argument list.</p> <p>Static evaluation works with plain static types as well as general types used in conjunction with <code>type</code>, <code>isinstance</code> or <code>hasattr</code>.</p>"}]}